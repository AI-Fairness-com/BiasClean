# -*- coding: utf-8 -*-
"""biasclean_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VkcJ0Ak4cZ6u8mZMYqeabisIR6wPinxV
"""

"""
Flask Web Wrapper for Universal BiasClean Pipeline - biasclean_app.py
Production Deployment for Render.com
Author: CS Principal Engineer with 20 years Python experience
"""

import os
import json
import tempfile
import traceback
from datetime import datetime
from typing import Dict, Any

import pandas as pd
from flask import Flask, request, jsonify, render_template

# Import your pipeline (adjusted for deployment)
# Note: We're removing Colab/UI dependencies while keeping core logic
from biasclean_7 import UniversalBiasClean, DOMAIN_CONFIGS

# ============================================================================
# FLASK APP CONFIGURATION
# ============================================================================

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max file size
app.config['UPLOAD_FOLDER'] = tempfile.gettempdir()

# ============================================================================
# ROUTES
# ============================================================================

@app.route('/')
def index():
    """Serve the main interface"""
    return render_template('upload_biasclean.html')


@app.route('/analyze', methods=['POST'])
def analyze():
    """Process CSV file and run bias analysis"""
    try:
        # Validate file upload
        if 'file' not in request.files:
            return jsonify({
                'error': 'No file uploaded',
                'details': 'Please select a CSV file'
            }), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({
                'error': 'No file selected',
                'details': 'Please select a CSV file'
            }), 400

        if not file.filename.lower().endswith('.csv'):
            return jsonify({
                'error': 'Invalid file type',
                'details': 'Please upload a CSV file'
            }), 400

        # Get parameters
        domain = request.form.get('domain', 'justice')
        target_column = request.form.get('target_column', None)
        if target_column == '':
            target_column = None

        threshold = request.form.get('threshold', '0.80')
        try:
            threshold = float(threshold)
            threshold = max(0.0, min(1.0, threshold))
        except ValueError:
            threshold = 0.80

        # Save uploaded file
        temp_file = tempfile.NamedTemporaryFile(
            suffix='.csv',
            delete=False,
            dir=app.config['UPLOAD_FOLDER']
        )
        file.save(temp_file.name)
        temp_file.close()

        # Read CSV
        try:
            df = pd.read_csv(temp_file.name)
        except Exception as e:
            os.unlink(temp_file.name)
            return jsonify({
                'error': 'Failed to read CSV file',
                'details': str(e)
            }), 400

        # Initialize pipeline
        pipeline = UniversalBiasClean(domain=domain)

        # Process dataset
        results = pipeline.process_dataset(
            df=df,
            target_column=target_column,
            auto_approve_threshold=threshold
        )

        # Generate corrected dataset file
        corrected_df = results.get('corrected_df')
        if corrected_df is not None:
            output_filename = f"biasclean_corrected_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            output_path = os.path.join(app.config['UPLOAD_FOLDER'], output_filename)
            corrected_df.to_csv(output_path, index=False)
            download_url = f"/download/{output_filename}"
        else:
            download_url = None

        # Extract key metrics for response
        diagnostics = results.get('diagnostics', {})
        validation = results.get('validation', {})

        initial_bias = diagnostics.get('initial_bias_score', 0)
        final_bias = diagnostics.get('final_bias_score', initial_bias)
        improvement = ((initial_bias - final_bias) / initial_bias * 100) if initial_bias > 0 else 0

        # Get biased features
        biased_features = []
        feature_tests = diagnostics.get('feature_tests', {})
        for feature, test in feature_tests.items():
            if test.get('significant_bias', False):
                biased_features.append(feature)

        # Clean up uploaded file
        os.unlink(temp_file.name)

        return jsonify({
            'success': True,
            'domain': domain,
            'records_processed': len(df),
            'columns_analyzed': len(df.columns),
            'initial_bias': initial_bias,
            'final_bias': final_bias,
            'improvement': improvement,
            'significant_biases': len(biased_features),
            'biased_features': biased_features,
            'data_retention': validation.get('data_integrity', {}).get('retention_rate', 100),
            'download_url': download_url,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        # Clean up temp files if they exist
        if 'temp_file' in locals() and os.path.exists(temp_file.name):
            os.unlink(temp_file.name)

        return jsonify({
            'error': 'Pipeline execution failed',
            'details': str(e),
            'traceback': traceback.format_exc()
        }), 500


@app.route('/download/<filename>', methods=['GET'])
def download(filename):
    """Serve corrected dataset for download"""
    try:
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)

        if not os.path.exists(file_path):
            return jsonify({
                'error': 'File not found',
                'details': 'The requested file has expired or was deleted'
            }), 404

        # Check if file is a CSV (security)
        if not filename.lower().endswith('.csv'):
            return jsonify({
                'error': 'Invalid file type'
            }), 400

        # Return file for download
        from flask import send_file
        return send_file(
            file_path,
            as_attachment=True,
            download_name=f"biasclean_corrected_{datetime.now().strftime('%Y%m%d')}.csv",
            mimetype='text/csv'
        )

    except Exception as e:
        return jsonify({
            'error': 'Download failed',
            'details': str(e)
        }), 500


@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint for Render"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'service': 'Universal BiasClean v2.1',
        'domains_available': list(DOMAIN_CONFIGS.keys())
    })


# ============================================================================
# SCHEDULED CLEANUP (Optional - for production)
# ============================================================================

def cleanup_old_files(max_age_hours=1):
    """Remove old uploaded files"""
    try:
        now = datetime.now().timestamp()
        for filename in os.listdir(app.config['UPLOAD_FOLDER']):
            if filename.startswith('biasclean_'):
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                file_age = now - os.path.getmtime(filepath)
                if file_age > (max_age_hours * 3600):
                    os.unlink(filepath)
                    print(f"Cleaned up old file: {filename}")
    except Exception as e:
        print(f"Cleanup error: {e}")


# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

if __name__ == '__main__':
    # Create upload directory if it doesn't exist
    os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

    # Run cleanup on startup
    cleanup_old_files()

    # Start Flask server
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
