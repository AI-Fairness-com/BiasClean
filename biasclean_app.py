# -*- coding: utf-8 -*-
"""BiasClean_7_Web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1If6dqweptvq6MvQ0POjbAsnFsnpSgSWK

# Main Pipeline
"""

# -*- coding: utf-8 -*-
"""
Universal BiasClean Pipeline v2.1 - 7-DOMAIN EDITION
Weight-Prioritized Bias Mitigation with Proper Weight-Based Prioritization

Author: [Your Name]
Date: December 2025
License: [Your License]
"""

# ============================================================================
# IMPORTS
# ============================================================================

import pandas as pd
import numpy as np
import json
import os
import warnings
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from scipy.stats import fisher_exact, chi2_contingency
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display, HTML, Markdown

warnings.filterwarnings('ignore')

# ============================================================================
# DOMAIN CONFIGURATIONS (7 DOMAINS - UK 2025 METHODOLOGY)
# ============================================================================

DOMAIN_CONFIGS = {
    "justice": {
        "weights": {
            "Ethnicity": 0.25,
            "SocioeconomicStatus": 0.20,
            "Region": 0.15,
            "Age": 0.15,
            "MigrationStatus": 0.10,
            "DisabilityStatus": 0.10,
            "Gender": 0.05
        },
        "outcome_patterns": ["recid", "reoffend", "rearrest", "violat", "outcome", "target", "label"],
        "ontology_extensions": {},
        "report_labels": {
            "outcome": "Recidivism Rate",
            "title": "Justice Bias Analysis Report",
            "domain": "Justice"
        }
    },
    "health": {
        "weights": {
            "Ethnicity": 0.25,
            "SocioeconomicStatus": 0.20,
            "Region": 0.10,
            "Age": 0.10,
            "MigrationStatus": 0.05,
            "DisabilityStatus": 0.15,
            "Gender": 0.15
        },
        "outcome_patterns": ["diagnosis", "mortality", "readmission", "stage", "outcome", "target", "triage", "screening", "positive", "negative", "case", "control"],
        "ontology_extensions": {
            "ClinicalFactors": {
                "patterns": ["bmi", "smoking", "history", "medication", "treatment", "therapy", "symptom", "comorbid"],
                "data_types": ["object", "int64", "float64"]
            }
        },
        "report_labels": {
            "outcome": "Diagnosis Rate",
            "title": "Healthcare Bias Analysis Report",
            "domain": "Health"
        }
    },
    "finance": {
        "weights": {
            "Ethnicity": 0.20,
            "SocioeconomicStatus": 0.30,
            "Region": 0.20,
            "Age": 0.10,
            "MigrationStatus": 0.05,
            "DisabilityStatus": 0.05,
            "Gender": 0.10
        },
        "outcome_patterns": ["approval", "default", "credit", "loan", "risk", "score", "interest", "payment", "outcome", "target", "label"],
        "ontology_extensions": {
            "FinancialFactors": {
                "patterns": ["income", "debt", "balance", "asset", "liability", "expense", "salary", "employment"],
                "data_types": ["int64", "float64"]
            }
        },
        "report_labels": {
            "outcome": "Approval Rate",
            "title": "Financial Bias Analysis Report",
            "domain": "Finance"
        }
    },
    "hiring": {
        "weights": {
            "Ethnicity": 0.25,
            "SocioeconomicStatus": 0.15,
            "Region": 0.10,
            "Age": 0.10,
            "MigrationStatus": 0.05,
            "DisabilityStatus": 0.15,
            "Gender": 0.20
        },
        "outcome_patterns": ["hire", "offer", "selection", "promotion", "recruitment", "shortlist", "interview", "success", "outcome", "target", "label"],
        "ontology_extensions": {
            "ProfessionalFactors": {
                "patterns": ["experience", "education", "qualification", "skill", "certification", "degree", "resume", "cv"],
                "data_types": ["object", "int64", "float64"]
            }
        },
        "report_labels": {
            "outcome": "Hiring Rate",
            "title": "Hiring Bias Analysis Report",
            "domain": "Hiring"
        }
    },
    "education": {
        "weights": {
            "Ethnicity": 0.20,
            "SocioeconomicStatus": 0.25,
            "Region": 0.15,
            "Age": 0.10,
            "MigrationStatus": 0.05,
            "DisabilityStatus": 0.15,
            "Gender": 0.10
        },
        "outcome_patterns": ["admission", "grade", "attainment", "graduation", "retention", "exclusion", "enrollment", "placement", "outcome", "target", "label", "admitted"],
        "ontology_extensions": {
            "AcademicFactors": {
                "patterns": ["test_score", "gpa", "attendance", "participation", "assignment", "exam", "course", "qualification"],
                "data_types": ["object", "int64", "float64"]
            }
        },
        "report_labels": {
            "outcome": "Admission Rate",
            "title": "Education Bias Analysis Report",
            "domain": "Education"
        }
    },
    "business": {
        "weights": {
            "Ethnicity": 0.25,
            "SocioeconomicStatus": 0.15,
            "Region": 0.15,
            "Age": 0.10,
            "MigrationStatus": 0.05,
            "DisabilityStatus": 0.10,
            "Gender": 0.20
        },
        "outcome_patterns": ["funding", "investment", "grant", "contract", "partnership", "procurement", "approval", "success", "outcome", "target", "label"],
        "ontology_extensions": {
            "BusinessFactors": {
                "patterns": ["revenue", "profit", "employees", "turnover", "assets", "liabilities"],
                "data_types": ["int64", "float64"]
            }
        },
        "report_labels": {
            "outcome": "Funding Rate",
            "title": "Business Bias Analysis Report",
            "domain": "Business"
        }
    },
    "governance": {
        "weights": {
            "Ethnicity": 0.25,
            "SocioeconomicStatus": 0.15,
            "Region": 0.15,
            "Age": 0.05,
            "MigrationStatus": 0.10,
            "DisabilityStatus": 0.10,
            "Gender": 0.20
        },
        "outcome_patterns": ["election", "appointment", "selection", "representation", "participation", "vote", "position", "outcome", "target", "label", "elected", "appointed", "selected"],
        "ontology_extensions": {
            "GovernanceFactors": {
                "patterns": ["tenure", "experience", "qualification", "endorsement", "support", "constituency", "campaign", "policy", "budget", "legislation"],
                "data_types": ["object", "int64", "float64"]
            }
        },
        "report_labels": {
            "outcome": "Selection Rate",
            "title": "Governance Bias Analysis Report",
            "domain": "Governance"
        }
    }
}

# ============================================================================
# 1. HIERARCHICAL MAPPER (Domain-Aware - 7 DOMAINS)
# ============================================================================

class HierarchicalMapper:
    """3-tier hierarchical feature mapper: Universal → Domain → Jurisdiction"""

    def __init__(self, domain="justice"):
        self.domain = domain
        self.config = DOMAIN_CONFIGS.get(domain, DOMAIN_CONFIGS["justice"])

        # Universal ontology (highest priority) - SAME FOR ALL DOMAINS
        self.universal_ontology = {
            "Age": {
                "patterns": ["age", "birth_year", "dob", "date_of_birth", "age_at", "years_old"],
                "data_types": ["int64", "float64"]
            },
            "Ethnicity": {
                "patterns": ["race", "ethnicity", "ethnic", "racial"],
                "value_mappings": {
                    "African-American": ["black", "african american", "aa", "afr_am"],
                    "Caucasian": ["white", "caucasian", "european"],
                    "Hispanic": ["latino", "latina", "latinx", "hispanic"],
                    "Asian": ["asian", "pacific islander", "api"],
                    "Native American": ["native", "indigenous", "american indian"],
                    "Other": ["other", "mixed", "multiracial"]
                }
            },
            "Gender": {
                "patterns": ["sex", "gender"],
                "value_mappings": {
                    "Male": ["m", "male", "man", "men"],
                    "Female": ["f", "female", "woman", "women"]
                }
            },
            "SocioeconomicStatus": {
                "patterns": ["income", "salary", "wage", "earnings", "wealth", "poverty", "ses"],
                "data_types": ["int64", "float64"]
            },
            "Region": {
                "patterns": ["region", "state", "county", "zipcode", "postcode", "location"],
                "data_types": ["object"]
            },
            "MigrationStatus": {
                "patterns": ["migration", "immigrant", "citizenship", "visa", "resident"],
                "data_types": ["object"]
            },
            "DisabilityStatus": {
                "patterns": ["disability", "handicap", "impairment", "condition"],
                "data_types": ["object"]
            }
        }

        # Domain-specific ontologies (7 DOMAINS)
        self.domain_ontologies = {
            "justice": {
                "outcome_patterns": self.config["outcome_patterns"],
                "contextual_patterns": {
                    "SocioeconomicStatus": ["prior", "count", "criminal_history", "arrest", "convict"],
                    "Region": ["charge", "offense", "county", "jurisdiction", "district"],
                    "MigrationStatus": ["citizenship", "origin", "nationality"]
                },
                "exclusion_patterns": ["id", "name", "case", "number", "docket", "person_id", "defendant_id"]
            },
            "health": {
                "outcome_patterns": self.config["outcome_patterns"],
                "contextual_patterns": {
                    "SocioeconomicStatus": ["bmi", "smoking", "history", "medication", "treatment"],
                    "DisabilityStatus": ["disability", "handicap", "impairment", "condition"],
                    "Region": ["postcode", "zipcode", "location", "clinic", "hospital"]
                },
                "exclusion_patterns": ["id", "name", "patient_id", "ssn", "mrn", "record_id"]
            },
            "finance": {
                "outcome_patterns": self.config["outcome_patterns"],
                "contextual_patterns": {
                    "SocioeconomicStatus": ["income", "salary", "debt", "balance", "asset", "liability"],
                    "Region": ["postcode", "zipcode", "state", "county", "branch"],
                    "MigrationStatus": ["citizenship", "visa", "resident", "immigration"]
                },
                "exclusion_patterns": ["id", "name", "applicant_id", "ssn", "account", "customer_id"]
            },
            "hiring": {
                "outcome_patterns": self.config["outcome_patterns"],
                "contextual_patterns": {
                    "SocioeconomicStatus": ["education", "qualification", "degree", "experience", "salary"],
                    "DisabilityStatus": ["disability", "accommodation", "accessibility"],
                    "Region": ["location", "postcode", "office", "branch"],
                    "MigrationStatus": ["visa", "citizenship", "residency", "work_permit"]
                },
                "exclusion_patterns": ["id", "name", "candidate_id", "applicant_id", "employee_id", "ssn"]
            },
            "education": {
                "outcome_patterns": self.config["outcome_patterns"],
                "contextual_patterns": {
                    "SocioeconomicStatus": ["income", "parent_income", "scholarship", "fee", "financial_aid"],
                    "DisabilityStatus": ["disability", "learning_difficulty", "special_needs", "support"],
                    "Region": ["postcode", "school_district", "catchment", "borough"],
                    "MigrationStatus": ["first_language", "english_additional", "immigrant", "asylum"]
                },
                "exclusion_patterns": ["id", "name", "student_id", "pupil_id", "upi", "nino"]
            },
            "business": {
                "outcome_patterns": self.config["outcome_patterns"],
                "contextual_patterns": {
                    "SocioeconomicStatus": ["revenue", "profit", "turnover", "assets", "employees", "capital"],
                    "Region": ["location", "jurisdiction", "market", "territory", "area", "zone"],
                    "MigrationStatus": ["ownership", "origin", "international", "foreign", "domestic"]
                },
                "exclusion_patterns": ["id", "name", "company_id", "business_id", "tax_id", "vat", "registration", "timestamp"]
            },
            "governance": {
                "outcome_patterns": self.config["outcome_patterns"],
                "contextual_patterns": {
                    "SocioeconomicStatus": ["donation", "contribution", "endorsement", "support", "campaign_budget"],
                    "Region": ["constituency", "district", "ward", "borough", "riding", "precinct"],
                    "MigrationStatus": ["citizenship", "residency", "eligibility", "nationality"]
                },
                "exclusion_patterns": ["id", "name", "candidate_id", "official_id", "member_id", "voter_id", "ballot_id"]
            }
        }

        # Get domain-specific ontology
        self.domain_ontology = self.domain_ontologies.get(domain, self.domain_ontologies["justice"])

    def map_column(self, column_name: str, sample_values: pd.Series) -> Dict:
        """Map a single column using 3-tier hierarchical rules"""
        col_lower = column_name.lower()

        # TIER 1: Universal attributes (highest priority)
        for feature, config in self.universal_ontology.items():
            for pattern in config["patterns"]:
                if pattern in col_lower:
                    # Validate with sample values
                    value_score = self._validate_values(sample_values, config)
                    confidence = 0.85 + (value_score * 0.1)

                    return {
                        "feature": feature,
                        "confidence": min(confidence, 0.98),
                        "tier": "universal",
                        "justification": f"Column name '{column_name}' matches universal {feature} pattern",
                        "pattern_matched": pattern
                    }

        # TIER 2: Domain-specific (outcome detection)
        for pattern in self.domain_ontology["outcome_patterns"]:
            if pattern in col_lower:
                if sample_values.nunique() == 2:  # Binary outcome
                    return {
                        "feature": "__outcome__",
                        "confidence": 0.90,
                        "tier": "domain",
                        "justification": f"Binary outcome variable with pattern '{pattern}'",
                        "is_outcome": True
                    }
                else:
                    return {
                        "feature": "__outcome__",
                        "confidence": 0.70,
                        "tier": "domain",
                        "justification": f"Potential outcome variable (requires binarization)",
                        "requires_binarization": True
                    }

        # TIER 2: Contextual features (DOMAIN-SPECIFIC)
        for feature_type, patterns in self.domain_ontology["contextual_patterns"].items():
            for pattern in patterns:
                if pattern in col_lower:
                    return {
                        "feature": feature_type,
                        "confidence": 0.75,
                        "tier": "domain",
                        "justification": f"Matches {feature_type} pattern '{pattern}'"
                    }

        # Exclusion patterns
        for pattern in self.domain_ontology["exclusion_patterns"]:
            if pattern in col_lower:
                return {
                    "feature": "__exclude__",
                    "confidence": 0.85,
                    "tier": "exclusion",
                    "justification": f"Identifier/administrative column (pattern: '{pattern}')"
                }

        # No match found
        return {
            "feature": None,
            "confidence": 0.20,
            "tier": "unknown",
            "justification": "No semantic pattern match found - requires manual review"
        }

    def _validate_values(self, sample_values: pd.Series, config: Dict) -> float:
        """Validate sample values against expected patterns"""
        if "value_mappings" in config:
            expected_values = set()
            for canonical, aliases in config["value_mappings"].items():
                expected_values.update([v.lower() for v in aliases])

            sample_set = set([str(v).lower() for v in sample_values.dropna().head(50)])
            if sample_set:
                overlap = len(sample_set & expected_values) / len(sample_set)
                return overlap

        if "data_types" in config and pd.api.types.is_numeric_dtype(sample_values):
            return 1.0

        return 0.5

    def map_dataset(self, df: pd.DataFrame) -> Dict[str, Dict]:
        """Map all columns in dataset"""
        mappings = {}
        for column in df.columns:
            sample = df[column].dropna()
            mappings[column] = self.map_column(column, sample)
        return mappings

# ============================================================================
# 2. CONSTRAINT VALIDATOR
# ============================================================================

class ConstraintValidator:
    """Statistical constraint validation for reliable fairness analysis"""

    def __init__(self):
        self.min_samples_per_group = 50
        self.min_total_records = 500
        self.max_missing_rate = 0.3

    def validate_outcome(self, df: pd.DataFrame, column: str) -> Dict:
        """Validate outcome variable suitability"""
        result = {
            "valid": True,
            "warnings": [],
            "errors": [],
            "statistics": {}
        }

        if column not in df.columns:
            result["valid"] = False
            result["errors"].append(f"Column '{column}' not found in dataset")
            return result

        clean_series = df[column].dropna()
        unique_count = clean_series.nunique()

        result["statistics"]["unique_values"] = unique_count
        result["statistics"]["total_samples"] = len(clean_series)

        # Must be binary
        if unique_count != 2:
            result["warnings"].append(f"Outcome has {unique_count} unique values (expected: 2)")
            if unique_count > 5:
                result["valid"] = False
                result["errors"].append("Too many unique values for binary outcome")

        # Check balance
        if unique_count == 2:
            positive_rate = clean_series.mean()
            result["statistics"]["positive_rate"] = positive_rate

            if not (0.05 <= positive_rate <= 0.95):
                result["warnings"].append(f"Class imbalance: {positive_rate:.1%} positive rate")

        # Check missing values
        missing_rate = df[column].isna().mean()
        result["statistics"]["missing_rate"] = missing_rate

        if missing_rate > 0.1:
            result["warnings"].append(f"High missing rate: {missing_rate:.1%}")

        return result

    def validate_protected_attribute(self, df: pd.DataFrame, column: str,
                                     target: str, feature_type: str = None) -> Dict:
        """Validate protected attribute for fairness analysis"""
        result = {
            "valid": True,
            "warnings": [],
            "errors": [],
            "statistics": {}
        }

        if column not in df.columns or target not in df.columns:
            result["valid"] = False
            result["errors"].append("Required columns not found")
            return result

        clean_data = df[[column, target]].dropna()

        # Check sample size per group
        value_counts = clean_data[column].value_counts()
        min_samples = value_counts.min()
        n_groups = len(value_counts)

        result["statistics"]["min_group_size"] = min_samples
        result["statistics"]["n_groups"] = n_groups

        if min_samples < self.min_samples_per_group:
            result["warnings"].append(
                f"Small group size: {min_samples} samples (recommended: {self.min_samples_per_group}+)"
            )

        # Check statistical relationship with outcome
        try:
            contingency = pd.crosstab(clean_data[column], clean_data[target])

            if contingency.shape == (2, 2):
                _, p_value = fisher_exact(contingency)
                test_used = "fisher-exact"
            else:
                chi2, p_value, _, _ = chi2_contingency(contingency)
                test_used = "chi-square"

            result["statistics"]["p_value"] = p_value
            result["statistics"]["test_used"] = test_used

            if p_value >= 0.05:
                result["warnings"].append(
                    f"Weak statistical relationship with outcome (p={p_value:.4f})"
                )

        except Exception as e:
            result["warnings"].append(f"Statistical test failed: {str(e)}")

        return result

# ============================================================================
# 3. USER CONFIRMATION UI (AUTO-APPROVAL MODE)
# ============================================================================

class MappingConfirmationUI:
    """CLI interface for mapping approval with auto-approval capability"""

    def __init__(self):
        self.approved_mappings = {}
        self.rejected_mappings = []

    def auto_approve_high_confidence(self, proposals: Dict,
                                    threshold: float = 0.80) -> Dict:
        """Auto-approve high-confidence mappings for production"""
        print(f"\n{'='*80}")
        print(f"AUTO-APPROVAL MODE (Confidence Threshold: {threshold:.0%})")
        print(f"{'='*80}\n")

        approved_count = 0
        rejected_count = 0

        for column, candidates in proposals.items():
            if not candidates:
                self.rejected_mappings.append(column)
                rejected_count += 1
                continue

            best = max(candidates, key=lambda x: x["confidence"])
            validation = best.get("validation", {})
            confidence = best["confidence"]
            feature = best["feature"]

            # Auto-approve criteria
            should_approve = (
                confidence >= threshold and
                validation.get("valid", True) and
                feature not in [None, "__exclude__"] and
                len(validation.get("errors", [])) == 0
            )

            if should_approve:
                self.approved_mappings[column] = {
                    **best,
                    "auto_approved": True,
                    "threshold_used": threshold
                }

                icon = "✅"
                print(f"{icon} {column:25} → {feature:20} ({confidence:.0%})")
                approved_count += 1
            else:
                self.rejected_mappings.append(column)

                # Determine reason
                reasons = []
                if confidence < threshold:
                    reasons.append(f"low confidence ({confidence:.0%})")
                if not validation.get("valid", True):
                    reasons.append("validation failed")
                if feature in [None, "__exclude__"]:
                    reasons.append("excluded/unknown")
                if validation.get("errors"):
                    reasons.append("has errors")

                icon = "⏭️"
                print(f"{icon} {column:25}   SKIPPED ({', '.join(reasons)})")
                rejected_count += 1

        print(f"\n{'='*80}")
        print(f"MAPPING SUMMARY")
        print(f"{'='*80}")
        print(f"✅ Approved: {approved_count} columns")
        print(f"⏭️  Skipped:  {rejected_count} columns")
        print(f"{'='*80}\n")

        return self.approved_mappings

# ============================================================================
# 4. BIASCLEAN ENGINE (FIXED - Weight-Based Prioritization)
# ============================================================================

class BiasCleanEngine:
    """Core bias detection and mitigation engine with proper weight prioritization"""

    def __init__(self, domain_weights: Dict[str, float]):
        self.domain_weights = domain_weights
        self._feature_map = {}
        self._target_column = None

    def score(self, df: pd.DataFrame, target_column: str) -> float:
        """Calculate weighted bias score (0-1, lower is better)"""
        total_score = 0.0
        meaningful_features = 0

        for feature, weight in self.domain_weights.items():
            disparity = self._calculate_disparity(df, feature, target_column)
            if disparity > 0:
                total_score += weight * disparity
                meaningful_features += 1

        if meaningful_features > 0:
            normalization = len(self.domain_weights) / meaningful_features
            total_score *= normalization

        return total_score

    def _calculate_disparity(self, df: pd.DataFrame, feature: str,
                           target_column: str) -> float:
        """Calculate outcome disparity for a protected feature"""
        column = self._feature_map.get(feature)
        if not column or column not in df.columns or target_column not in df.columns:
            return 0.0

        try:
            group_rates = {}
            for group in df[column].unique():
                if pd.isna(group):
                    continue
                group_data = df[df[column] == group]
                if len(group_data) >= 10:
                    rate = group_data[target_column].mean()
                    group_rates[str(group)] = rate

            if len(group_rates) < 2:
                return 0.0

            rates = np.array(list(group_rates.values()))
            mean_rate = np.mean(rates)

            if mean_rate == 0:
                return 0.0

            cv_disparity = np.std(rates) / mean_rate
            return min(cv_disparity, 1.0)

        except Exception:
            return 0.0

    def transform_industry(self, df: pd.DataFrame,
                         diagnostic_results: Dict) -> pd.DataFrame:
        """Apply bias mitigation with PROPER weight-prioritized rebalancing"""
        if not diagnostic_results.get("requires_mitigation", False):
            return df.copy()

        df_optimized = df.copy()
        target = self._target_column or diagnostic_results.get("target_column_used")

        # Get features with significant bias, sorted by weight (highest first)
        biased_features = []
        for feature, test_result in diagnostic_results.get("feature_tests", {}).items():
            if test_result.get("significant_bias", False):
                weight = self.domain_weights.get(feature, 0.05)
                biased_features.append((feature, weight))

        # FIXED: Sort by weight descending (highest weight = highest priority)
        biased_features.sort(key=lambda x: x[1], reverse=True)

        print(f"\n   WEIGHT-PRIORITIZED MITIGATION ORDER:")
        print(f"   {'Feature':<25} {'Weight':<10} {'Priority'} ")
        print(f"   {'-'*25} {'-'*10} {'-'*8}")
        for i, (feature, weight) in enumerate(biased_features, 1):
            print(f"   {feature:<25} {weight:<10.2f} #{i}")

        # Apply rebalancing in weight-priority order
        for feature, weight in biased_features:
            column = self._feature_map.get(feature)
            if column and column in df_optimized.columns:
                df_optimized = self._rebalance_feature_weighted(
                    df_optimized, column, target, weight
                )

        return df_optimized

    def _rebalance_feature_weighted(self, df: pd.DataFrame, column: str,
                                   target: str, weight: float) -> pd.DataFrame:
        """Rebalance a specific feature with weight-dependent intensity"""
        df_balanced = df.copy()
        group_stats = df.groupby(column)[target].agg(["mean", "count"])
        overall_mean = df[target].mean()

        # FIXED: Use domain-specific max weight for normalization
        max_domain_weight = max(self.domain_weights.values()) if self.domain_weights else 0.25

        # Weight factor normalized to domain max (reflects relative importance)
        weight_factor = weight / max_domain_weight

        # Disparity threshold: higher weight = lower threshold (catch more cases)
        disparity_threshold = 0.08 * (1.5 - weight_factor)  # Range: 0.04 to 0.12

        # Removal rate: higher weight = more removal
        removal_rate = 0.05 * (1.0 + weight_factor)  # Range: 0.05 to 0.10

        # Addition rate: higher weight = more addition
        addition_rate = 0.08 * (1.0 + weight_factor)  # Range: 0.08 to 0.16

        # Minimum group size: higher weight = lower threshold
        min_group_size = int(30 * (1.0 - weight_factor * 0.5))  # Range: 15 to 30

        print(f"\n     Rebalancing '{column}' (weight: {weight:.2f}, factor: {weight_factor:.2f})")
        print(f"       • Disparity threshold: {disparity_threshold:.3f}")
        print(f"       • Removal rate: {removal_rate:.3f}, Addition rate: {addition_rate:.3f}")
        print(f"       • Min group size: {min_group_size}")

        total_removed = 0
        total_added = 0

        for group, stats in group_stats.iterrows():
            group_mean = stats["mean"]
            group_size = stats["count"]

            # Use weight-adjusted thresholds
            if abs(group_mean - overall_mean) > disparity_threshold and group_size > min_group_size:
                group_mask = df[column] == group

                if group_mean > overall_mean:  # High outcome group
                    positives = df[group_mask & (df[target] == 1)]
                    if len(positives) > 10:
                        # Weight-dependent removal
                        remove_n = min(len(positives) // 10, int(group_size * removal_rate))
                        if remove_n > 0:
                            remove_idx = positives.sample(n=remove_n, random_state=42).index
                            df_balanced = df_balanced.drop(remove_idx)
                            total_removed += remove_n

                else:  # Low outcome group
                    positives = df[group_mask & (df[target] == 1)]
                    if len(positives) > 5:
                        # Weight-dependent addition
                        add_n = min(len(positives) // 5, int(group_size * addition_rate))
                        if add_n > 0:
                            add_samples = positives.sample(n=add_n, replace=True, random_state=42)
                            df_balanced = pd.concat([df_balanced, add_samples], ignore_index=True)
                            total_added += add_n

        print(f"       • Samples removed: {total_removed}, Samples added: {total_added}")

        return df_balanced

    # Keep original method for backward compatibility
    def _rebalance_feature(self, df: pd.DataFrame, column: str,
                          target: str) -> pd.DataFrame:
        """Original rebalancing (uses default weight = 0.05)"""
        return self._rebalance_feature_weighted(df, column, target, weight=0.05)

    def validate_industry_readiness(self, df_before: pd.DataFrame,
                                   df_after: pd.DataFrame,
                                   diagnostic_results: Dict) -> Dict:
        """Validate mitigation results with proper disparity calculation"""
        validation = {
            "fairness_improvement": {},
            "absolute_disparity_reduction": {},
            "initial_disparities": {},
            "final_disparities": {},
            "data_integrity": {
                "records_before": len(df_before),
                "records_after": len(df_after),
                "retention_rate": (len(df_after) / len(df_before)) * 100
            }
        }

        target = diagnostic_results.get("target_column_used")
        feature_tests = diagnostic_results.get("feature_tests", {})

        for feature, test_result in feature_tests.items():
            # Only calculate improvements for features that were actually mitigated
            if not test_result.get("significant_bias", False):
                continue

            # Get the actual column name from the test results
            column_name = test_result.get("column_name")
            if not column_name or column_name not in df_before.columns:
                continue

            # Calculate disparity using the actual column name
            before = self._calculate_disparity_direct(df_before, column_name, target)
            after = self._calculate_disparity_direct(df_after, column_name, target)

            validation["initial_disparities"][feature] = before
            validation["final_disparities"][feature] = after

            if before > 0:
                # Percentage improvement
                improvement = ((before - after) / before) * 100
                validation["fairness_improvement"][feature] = improvement

                # Absolute reduction
                absolute_reduction = before - after
                validation["absolute_disparity_reduction"][feature] = absolute_reduction

        return validation

    def _calculate_disparity_direct(self, df: pd.DataFrame, column: str,
                                  target_column: str) -> float:
        """Calculate disparity directly without feature map lookup"""
        if column not in df.columns or target_column not in df.columns:
            return 0.0

        try:
            group_rates = {}
            for group in df[column].unique():
                if pd.isna(group):
                    continue
                group_data = df[df[column] == group]
                if len(group_data) >= 10:
                    rate = group_data[target_column].mean()
                    group_rates[str(group)] = rate

            if len(group_rates) < 2:
                return 0.0

            rates = np.array(list(group_rates.values()))
            mean_rate = np.mean(rates)

            if mean_rate == 0:
                return 0.0

            cv_disparity = np.std(rates) / mean_rate
            return min(cv_disparity, 1.0)

        except Exception:
            return 0.0

# ============================================================================
# 5. VISUALIZATION ENGINE
# ============================================================================
class VisualizationEngine:
    """Generate comprehensive visualizations for bias analysis"""

    def __init__(self):
        sns.set_style("whitegrid")
        plt.rcParams['figure.figsize'] = (12, 6)

    def plot_disparity_comparison(self, original_df: pd.DataFrame,
                                  corrected_df: pd.DataFrame,
                                  feature_map: Dict, target: str,
                                  save_path: str = None):
        """Plot before/after disparity comparison"""
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))

        for idx, (df, title) in enumerate([(original_df, "Before Mitigation"),
                                           (corrected_df, "After Mitigation")]):
            ax = axes[idx]

            # Plot outcome rates by protected attributes
            for feature, column in feature_map.items():
                if column in df.columns:
                    rates = df.groupby(column)[target].mean()
                    rates.plot(kind='bar', ax=ax, alpha=0.7, label=feature)

            ax.set_title(title, fontsize=14, fontweight='bold')
            ax.set_ylabel("Outcome Rate", fontsize=12)
            ax.set_xlabel("Groups", fontsize=12)
            ax.legend(loc='upper right')
            ax.axhline(y=df[target].mean(), color='r', linestyle='--',
                      label='Overall Mean', alpha=0.5)
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        plt.show()

    def plot_feature_improvements(self, validation_results: Dict,
                                  save_path: str = None):
        """Plot fairness improvements by feature"""
        improvements = validation_results.get("fairness_improvement", {})

        if not improvements:
            print("No fairness improvements to visualize")
            return

        fig, ax = plt.subplots(figsize=(10, 6))

        features = list(improvements.keys())
        values = list(improvements.values())

        colors = ['green' if v > 0 else 'red' for v in values]

        ax.barh(features, values, color=colors, alpha=0.7)
        ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)
        ax.set_xlabel('Improvement (%)', fontsize=12)
        ax.set_title('Fairness Improvements by Protected Feature',
                    fontsize=14, fontweight='bold')
        ax.grid(axis='x', alpha=0.3)

        # Add value labels
        for i, v in enumerate(values):
            ax.text(v + (2 if v > 0 else -2), i, f'{v:+.1f}%',
                   va='center', ha='left' if v > 0 else 'right')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        plt.show()

    def plot_data_integrity(self, validation_results: Dict,
                           save_path: str = None):
        """Plot data integrity metrics"""
        integrity = validation_results.get("data_integrity", {})

        fig, ax = plt.subplots(figsize=(8, 6))

        before = integrity.get("records_before", 0)
        after = integrity.get("records_after", 0)
        retention = integrity.get("retention_rate", 100)

        ax.bar(['Before Mitigation', 'After Mitigation'],
               [before, after], color=['#3498db', '#2ecc71'], alpha=0.7)

        ax.set_ylabel('Number of Records', fontsize=12)
        ax.set_title('Data Integrity: Record Count',
                    fontsize=14, fontweight='bold')

        # Add retention rate annotation
        ax.text(0.5, max(before, after) * 0.95,
               f'Retention Rate: {retention:.1f}%',
               ha='center', fontsize=12,
               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        # Add value labels
        for i, v in enumerate([before, after]):
            ax.text(i, v + (max(before, after) * 0.02), f'{v:,}',
                   ha='center', va='bottom', fontsize=11)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        plt.show()

# ============================================================================
# 6. REPORT GENERATOR
# ============================================================================

class ReportGenerator:
    """Generate comprehensive human-readable reports"""

    def __init__(self, config=None):
        self.config = config or DOMAIN_CONFIGS["justice"]

    def generate_html_report(self, results: Dict, output_file: str = "biasclean_report.html"):
        """Generate comprehensive HTML report"""

        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>BiasClean Analysis Report - {self.config["report_labels"]["domain"]}</title>
            <style>
                body {{
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                    max-width: 1200px;
                    margin: 0 auto;
                    padding: 20px;
                    background-color: #f5f5f5;
                }}
                .header {{
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white;
                    padding: 30px;
                    border-radius: 10px;
                    margin-bottom: 30px;
                }}
                .section {{
                    background: white;
                    padding: 25px;
                    margin-bottom: 20px;
                    border-radius: 8px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }}
                .metric {{
                    display: inline-block;
                    background: #f8f9fa;
                    padding: 15px 25px;
                    margin: 10px;
                    border-radius: 5px;
                    border-left: 4px solid #667eea;
                }}
                .metric-value {{
                    font-size: 28px;
                    font-weight: bold;
                    color: #667eea;
                }}
                .metric-label {{
                    font-size: 14px;
                    color: #666;
                    margin-top: 5px;
                }}
                .success {{
                    color: #27ae60;
                    font-weight: bold;
                }}
                .warning {{
                    color: #f39c12;
                    font-weight: bold;
                }}
                .error {{
                    color: #e74c3c;
                    font-weight: bold;
                }}
                table {{
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 15px;
                }}
                th, td {{
                    padding: 12px;
                    text-align: left;
                    border-bottom: 1px solid #ddd;
                }}
                th {{
                    background-color: #667eea;
                    color: white;
                }}
                tr:hover {{
                    background-color: #f5f5f5;
                }}
                .footer {{
                    text-align: center;
                    color: #666;
                    margin-top: 40px;
                    padding: 20px;
                }}
                .weight-badge {{
                    display: inline-block;
                    background: #e3f2fd;
                    color: #1976d2;
                    padding: 2px 8px;
                    border-radius: 12px;
                    font-size: 12px;
                    margin-left: 8px;
                }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>{self.config["report_labels"]["title"]}</h1>
                <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p>Domain: {self.config["report_labels"]["domain"]} | Version: 2.1 (Fixed Weight Prioritization)</p>
            </div>
        """

        # Executive Summary
        diagnostics = results.get("diagnostics", {})
        validation = results.get("validation", {})

        initial_bias = diagnostics.get("initial_bias_score", 0)
        final_bias = diagnostics.get("final_bias_score", initial_bias)
        improvement = ((initial_bias - final_bias) / initial_bias * 100) if initial_bias > 0 else 0

        html_content += f"""
            <div class="section">
                <h2>Executive Summary</h2>
                <div class="metric">
                    <div class="metric-value">{initial_bias:.3f} → {final_bias:.3f}</div>
                    <div class="metric-label">Bias Score</div>
                </div>
                <div class="metric">
                    <div class="metric-value {'success' if improvement > 0 else 'error'}">{improvement:+.1f}%</div>
                    <div class="metric-label">Overall Improvement</div>
                </div>
                <div class="metric">
                    <div class="metric-value">{diagnostics.get('significant_bias_count', 0)}</div>
                    <div class="metric-label">Significant Biases</div>
                </div>
                <div class="metric">
                    <div class="metric-value">{validation.get('data_integrity', {}).get('retention_rate', 100):.1f}%</div>
                    <div class="metric-label">Data Retention</div>
                </div>
            </div>
        """

        # Feature Mappings with Weights
        mappings = results.get("mappings", {})
        domain_weights = self.config.get("weights", {})

        html_content += """
            <div class="section">
                <h2>Feature Mappings & Weights</h2>
                <table>
                    <tr>
                        <th>Original Column</th>
                        <th>Mapped Feature</th>
                        <th>Weight</th>
                        <th>Confidence</th>
                        <th>Tier</th>
                    </tr>
        """

        for col, mapping in mappings.items():
            feature = mapping.get("feature", "Unknown")
            confidence = mapping.get("confidence", 0) * 100
            tier = mapping.get("tier", "unknown")
            weight = domain_weights.get(feature, "N/A")
            weight_display = f"{weight:.2f}" if isinstance(weight, (int, float)) else weight

            html_content += f"""
                    <tr>
                        <td>{col}</td>
                        <td><strong>{feature}</strong></td>
                        <td>{weight_display}</td>
                        <td>{confidence:.0f}%</td>
                        <td><span class="{'success' if tier=='universal' else 'warning'}">{tier}</span></td>
                    </tr>
            """

        html_content += """
                </table>
            </div>
        """

        # Fairness Improvements
        improvements = validation.get("fairness_improvement", {})
        if improvements:
            html_content += """
                <div class="section">
                    <h2>Fairness Improvements by Feature (Weight-Prioritized)</h2>
                    <table>
                        <tr>
                            <th>Protected Feature</th>
                            <th>Weight</th>
                            <th>Improvement</th>
                            <th>Status</th>
                        </tr>
            """

            # Sort improvements by weight (highest first)
            sorted_improvements = sorted(
                improvements.items(),
                key=lambda x: domain_weights.get(x[0], 0),
                reverse=True
            )

            for feature, imp_value in sorted_improvements:
                status = "Improved" if imp_value > 0 else "Worsened"
                status_class = "success" if imp_value > 0 else "error"
                weight = domain_weights.get(feature, "N/A")
                weight_display = f"{weight:.2f}" if isinstance(weight, (int, float)) else weight

                html_content += f"""
                        <tr>
                            <td><strong>{feature}</strong></td>
                            <td>{weight_display}</td>
                            <td><span class="{status_class}">{imp_value:+.1f}%</span></td>
                            <td>{status}</td>
                        </tr>
                """

            html_content += """
                    </table>
                </div>
            """

        # Statistical Tests
        feature_tests = diagnostics.get("feature_tests", {})
        if feature_tests:
            html_content += """
                <div class="section">
                    <h2>Statistical Tests</h2>
                    <table>
                        <tr>
                            <th>Feature</th>
                            <th>Weight</th>
                            <th>Test Used</th>
                            <th>P-Value</th>
                            <th>Significant Bias</th>
                        </tr>
            """

            for feature, test in feature_tests.items():
                p_val = test.get("p_value", 1.0)
                sig = test.get("significant_bias", False)
                test_used = test.get("test_used", "N/A")
                weight = domain_weights.get(feature, "N/A")
                weight_display = f"{weight:.2f}" if isinstance(weight, (int, float)) else weight

                html_content += f"""
                        <tr>
                            <td><strong>{feature}</strong></td>
                            <td>{weight_display}</td>
                            <td>{test_used}</td>
                            <td>{p_val:.6f}</td>
                            <td><span class="{'error' if sig else 'success'}">{'Yes' if sig else 'No'}</span></td>
                        </tr>
                """

            html_content += """
                </table>
            </div>
        """

        # Footer
        html_content += """
            <div class="footer">
                <p>Generated by Universal BiasClean v2.1 - Weight-Prioritized Edition</p>
                <p>Hierarchical Taxonomy + Constraint Validation Framework</p>
                <p><strong>Fixed:</strong> Proper weight-based feature prioritization across all domains</p>
            </div>
        </body>
        </html>
        """

        # Save to file
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"HTML report saved to: {output_file}")
        return output_file

    def print_console_report(self, results: Dict):
        """Print comprehensive console report"""
        print("\n" + "="*80)
        print("BIASCLEAN ANALYSIS REPORT")
        print("="*80)

        diagnostics = results.get("diagnostics", {})
        validation = results.get("validation", {})

        # Executive Summary
        print("\nEXECUTIVE SUMMARY")
        print("-"*80)

        initial_bias = diagnostics.get("initial_bias_score", 0)
        final_bias = diagnostics.get("final_bias_score", initial_bias)
        improvement = ((initial_bias - final_bias) / initial_bias * 100) if initial_bias > 0 else 0

        print(f"Initial Bias Score:     {initial_bias:.4f}")
        print(f"Final Bias Score:       {final_bias:.4f}")
        print(f"Overall Improvement:    {improvement:+.1f}%")
        print(f"Significant Biases:     {diagnostics.get('significant_bias_count', 0)}")

        # Data Integrity
        integrity = validation.get("data_integrity", {})
        print(f"\nRecords Before:         {integrity.get('records_before', 0):,}")
        print(f"Records After:          {integrity.get('records_after', 0):,}")
        print(f"Retention Rate:         {integrity.get('retention_rate', 100):.1f}%")

        # Feature Improvements with Weights
        improvements = validation.get("fairness_improvement", {})
        if improvements:
            print("\nFAIRNESS IMPROVEMENTS BY FEATURE (Weight-Prioritized)")
            print("-"*80)
            # Sort by weight
            sorted_improvements = sorted(
                improvements.items(),
                key=lambda x: self.config["weights"].get(x[0], 0),
                reverse=True
            )
            for feature, imp_value in sorted_improvements:
                weight = self.config["weights"].get(feature, "N/A")
                icon = "✅" if imp_value > 0 else "⚠️"
                print(f"{icon} {feature:25} Weight: {weight:<5} {imp_value:+.1f}%")

        # Mappings Summary
        mappings = results.get("mappings", {})
        print(f"\nFEATURE MAPPINGS")
        print("-"*80)
        print(f"Total Approved:         {len(mappings)}")

        tier_counts = {}
        for mapping in mappings.values():
            tier = mapping.get("tier", "unknown")
            tier_counts[tier] = tier_counts.get(tier, 0) + 1

        for tier, count in tier_counts.items():
            print(f"  • {tier.title():15}  {count}")

        print("\n" + "="*80)

# ============================================================================
# 7. UNIVERSAL BIASCLEAN PIPELINE (Main Orchestrator)
# ============================================================================

class UniversalBiasClean:
    """Main orchestration pipeline for Universal BiasClean"""

    def __init__(self, domain: str = "justice", jurisdiction: Optional[str] = None):
        self.domain = domain
        self.jurisdiction = jurisdiction
        self.config = DOMAIN_CONFIGS.get(domain, DOMAIN_CONFIGS["justice"])

        # Initialize components
        self.mapper = HierarchicalMapper(domain=domain)
        self.validator = ConstraintValidator()
        self.ui = MappingConfirmationUI()
        self.viz = VisualizationEngine()
        self.reporter = ReportGenerator(self.config)

        # Domain-specific weights
        self.engine = BiasCleanEngine(self.config["weights"])

        # State variables
        self.original_df = None
        self.corrected_df = None
        self.approved_mappings = {}
        self.results = {}

        print(f"\n{'='*80}")
        print(f"UNIVERSAL BIASCLEAN v2.1 - INITIALIZED")
        print(f"{'='*80}")
        print(f"   Domain:        {domain.upper()}")
        print(f"   Jurisdiction:  {jurisdiction or 'Default'}")
        print(f"   Framework:     Hierarchical Taxonomy + Constraint Validation")
        print(f"   Fixed:         Weight-Based Prioritization Active")
        print(f"{'='*80}\n")

    def process_dataset(self, file_path: str = None, df: pd.DataFrame = None,
                       target_column: Optional[str] = None,
                       auto_approve_threshold: float = 0.80) -> Dict[str, Any]:
        """
        Complete pipeline execution

        Args:
            file_path: Path to CSV file (optional if df provided)
            df: DataFrame to process (optional if file_path provided)
            target_column: Outcome variable column name (optional, auto-detected)
            auto_approve_threshold: Confidence threshold for auto-approval

        Returns:
            Complete results dictionary
        """
        try:
            # ================================================================
            # PHASE 1: DATASET LOADING
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 1: DATASET LOADING")
            print(f"{'='*80}")

            if df is not None:
                self.original_df = df.copy()
                print(f"Loaded DataFrame from memory")
            elif file_path:
                self.original_df = pd.read_csv(file_path)
                print(f"Loaded CSV: {file_path}")
            else:
                raise ValueError("Must provide either file_path or df")

            print(f"   Records:  {len(self.original_df):,}")
            print(f"   Columns:  {len(self.original_df.columns)}")
            print(f"   Memory:   {self.original_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

            # ================================================================
            # PHASE 2: HIERARCHICAL MAPPING
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 2: HIERARCHICAL FEATURE MAPPING")
            print(f"{'='*80}")

            raw_mappings = self.mapper.map_dataset(self.original_df)

            # Count by tier
            tier_counts = {}
            for mapping in raw_mappings.values():
                tier = mapping.get("tier", "unknown")
                tier_counts[tier] = tier_counts.get(tier, 0) + 1

            print(f"   Analyzed {len(raw_mappings)} columns:")
            for tier, count in sorted(tier_counts.items()):
                print(f"     • {tier.title()}: {count}")

            # ================================================================
            # PHASE 3: CONSTRAINT VALIDATION
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 3: CONSTRAINT VALIDATION")
            print(f"{'='*80}")

            # Determine target column
            if target_column and target_column in self.original_df.columns:
                final_target = target_column
                print(f"   Using specified target: '{final_target}'")
            else:
                # Auto-detect outcome column
                outcome_candidates = []
                for col, mapping in raw_mappings.items():
                    if mapping.get("feature") == "__outcome__":
                        outcome_candidates.append((col, mapping.get("confidence", 0)))

                if outcome_candidates:
                    # Sort by confidence and take best
                    outcome_candidates.sort(key=lambda x: x[1], reverse=True)
                    final_target = outcome_candidates[0][0]
                    print(f"   Auto-detected target: '{final_target}' (confidence: {outcome_candidates[0][1]:.0%})")
                else:
                    # Find any binary column - PRIORITIZE NUMERIC (0/1) over string
                    binary_candidates = []
                    for col in self.original_df.columns:
                        if self.original_df[col].nunique() == 2:
                            binary_candidates.append((col, pd.api.types.is_numeric_dtype(self.original_df[col])))

                    if binary_candidates:
                        # Sort: numeric True first, then string False
                        binary_candidates.sort(key=lambda x: x[1], reverse=True)
                        final_target = binary_candidates[0][0]
                        print(f"   Using binary column as target: '{final_target}'")
                    else:
                        raise ValueError("No suitable target column found. Please specify manually.")

            # Validate outcome
            outcome_validation = self.validator.validate_outcome(self.original_df, final_target)

            if outcome_validation.get("errors"):
                print(f"   Outcome validation errors:")
                for error in outcome_validation["errors"]:
                    print(f"      • {error}")

            if outcome_validation.get("warnings"):
                print(f"   Outcome validation warnings:")
                for warning in outcome_validation["warnings"][:3]:  # Show first 3
                    print(f"      • {warning}")

            # Validate all mappings
            validated_proposals = {}
            validation_summary = {"passed": 0, "warnings": 0, "errors": 0}

            for column, mapping in raw_mappings.items():
                if column == final_target:
                    validated_proposals[column] = [{
                        **mapping,
                        "feature": "__outcome__",
                        "validation": outcome_validation
                    }]
                else:
                    feature = mapping.get("feature")
                    if feature and feature not in ["__exclude__", None]:
                        validation = self.validator.validate_protected_attribute(
                            self.original_df, column, final_target, feature
                        )

                        if validation.get("errors"):
                            validation_summary["errors"] += 1
                        elif validation.get("warnings"):
                            validation_summary["warnings"] += 1
                        else:
                            validation_summary["passed"] += 1

                        validated_proposals[column] = [{
                            **mapping,
                            "validation": validation
                        }]
                    else:
                        validated_proposals[column] = [mapping]

            print(f"\n   Validation Summary:")
            print(f"     Passed:   {validation_summary['passed']}")
            print(f"     Warnings: {validation_summary['warnings']}")
            print(f"     Errors:   {validation_summary['errors']}")

            # ================================================================
            # PHASE 4: MAPPING CONFIRMATION (AUTO-APPROVAL)
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 4: MAPPING CONFIRMATION")
            print(f"{'='*80}")

            self.approved_mappings = self.ui.auto_approve_high_confidence(
                validated_proposals, threshold=auto_approve_threshold
            )

            if not self.approved_mappings:
                raise ValueError("No mappings approved. Lower threshold or check data quality.")

            # ================================================================
            # PHASE 5: PREPARE FOR BIAS ANALYSIS
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 5: PREPARATION FOR BIAS ANALYSIS")
            print(f"{'='*80}")

            # Build feature map (exclude outcome and excluded columns)
            feature_map = {}
            for column, mapping in self.approved_mappings.items():
                feature = mapping.get("feature")
                if feature and feature not in ["__outcome__", "__exclude__", None]:
                    feature_map[feature] = column

            self.engine._feature_map = feature_map
            self.engine._target_column = final_target

            print(f"   Target column: '{final_target}'")
            print(f"   Features for analysis (with domain weights):")
            for feature, column in feature_map.items():
                weight = self.config["weights"].get(feature, 0.05)
                print(f"     • {feature:25} ← {column:30} (weight: {weight:.2f})")

            # ================================================================
            # PHASE 6: BIAS DETECTION & STATISTICAL DIAGNOSIS
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 6: BIAS DETECTION & STATISTICAL DIAGNOSIS")
            print(f"{'='*80}")

            diagnostic_results = self._run_statistical_diagnosis(feature_map, final_target)

            print(f"\n   Initial Bias Score: {diagnostic_results['initial_bias_score']:.4f}")
            print(f"   Significant Biases: {diagnostic_results['significant_bias_count']}")

            if diagnostic_results.get("feature_tests"):
                print(f"\n   Statistical Tests (sorted by domain weight):")
                # Sort by weight
                sorted_tests = sorted(
                    diagnostic_results["feature_tests"].items(),
                    key=lambda x: self.config["weights"].get(x[0], 0),
                    reverse=True
                )
                for feature, test in sorted_tests:
                    sig = "SIGNIFICANT" if test.get("significant_bias") else "OK"
                    p_val = test.get("p_value", 1.0)
                    weight = self.config["weights"].get(feature, 0.05)
                    threshold = test.get("threshold_used", 0.05)  # Show weight-adjusted threshold
                    print(f"     • {feature:25} p={p_val:.6f}  {sig}  (weight: {weight:.2f}, threshold: {threshold:.3f})")

            # ================================================================
            # PHASE 7: BIAS MITIGATION (WEIGHT-PRIORITIZED)
            # ================================================================
            if diagnostic_results["requires_mitigation"]:
                print(f"\n{'='*80}")
                print("PHASE 7: WEIGHT-PRIORITIZED BIAS MITIGATION")
                print(f"{'='*80}")

                print(f"   Applying weight-prioritized rebalancing...")

                self.corrected_df = self.engine.transform_industry(
                    self.original_df, diagnostic_results
                )

                # Calculate final bias score
                final_bias = self.engine.score(self.corrected_df, final_target)
                diagnostic_results["final_bias_score"] = final_bias

                initial_bias = diagnostic_results["initial_bias_score"]
                improvement = ((initial_bias - final_bias) / initial_bias * 100) if initial_bias > 0 else 0

                print(f"\n   Bias Score: {initial_bias:.4f} → {final_bias:.4f}")
                print(f"   Improvement: {improvement:+.1f}%")

                # Validate results
                validation = self.engine.validate_industry_readiness(
                    self.original_df, self.corrected_df, diagnostic_results
                )

                print(f"\n   Data Integrity:")
                print(f"     • Records: {validation['data_integrity']['records_before']:,} → {validation['data_integrity']['records_after']:,}")
                print(f"     • Retention: {validation['data_integrity']['retention_rate']:.1f}%")

                if validation.get("fairness_improvement"):
                    print(f"\n   Fairness Improvements (sorted by weight):")
                    # Sort by weight
                    sorted_improvements = sorted(
                        validation["fairness_improvement"].items(),
                        key=lambda x: self.config["weights"].get(x[0], 0),
                        reverse=True
                    )
                    for feature, imp in sorted_improvements:
                        icon = "✅" if imp > 0 else "⚠️"
                        weight = self.config["weights"].get(feature, 0.05)
                        print(f"     {icon} {feature:25} {imp:+.1f}%  (weight: {weight:.2f})")

            else:
                print(f"\n{'='*80}")
                print("PHASE 7: NO MITIGATION NEEDED")
                print(f"{'='*80}")
                print("   No significant biases detected. Dataset is fair.")

                self.corrected_df = self.original_df.copy()
                diagnostic_results["final_bias_score"] = diagnostic_results["initial_bias_score"]
                validation = {
                    "fairness_improvement": {},
                    "data_integrity": {
                        "records_before": len(self.original_df),
                        "records_after": len(self.original_df),
                        "retention_rate": 100.0
                    }
                }

            # ================================================================
            # PHASE 8: RESULTS COMPILATION
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 8: COMPILING RESULTS")
            print(f"{'='*80}")

            self.results = {
                "original_df": self.original_df,
                "corrected_df": self.corrected_df,
                "mappings": self.approved_mappings,
                "diagnostics": diagnostic_results,
                "validation": validation,
                "target_column": final_target,
                "feature_map": feature_map,
                "metadata": {
                    "domain": self.domain,
                    "jurisdiction": self.jurisdiction,
                    "timestamp": datetime.now().isoformat(),
                    "auto_approve_threshold": auto_approve_threshold
                }
            }

            print(f"   Results compiled successfully")

            # ================================================================
            # PHASE 9: SAVE RESULTS
            # ================================================================
            self._save_results()

            # ================================================================
            # PHASE 10: GENERATE VISUALIZATIONS & REPORTS
            # ================================================================
            print(f"\n{'='*80}")
            print("PHASE 10: GENERATING VISUALIZATIONS & REPORTS")
            print(f"{'='*80}")

            # Generate visualizations
            try:
                print("\n   Generating visualizations...")

                # Disparity comparison
                self.viz.plot_disparity_comparison(
                    self.original_df, self.corrected_df,
                    feature_map, final_target,
                    save_path="biasclean_results/disparity_comparison.png"
                )

                # Fairness improvements
                if validation.get("fairness_improvement"):
                    self.viz.plot_feature_improvements(
                        validation,
                        save_path="biasclean_results/fairness_improvements.png"
                    )

                # Data integrity
                self.viz.plot_data_integrity(
                    validation,
                    save_path="biasclean_results/data_integrity.png"
                )

                print(f"   Visualizations saved to biasclean_results/")

            except Exception as e:
                print(f"   Visualization generation failed: {str(e)}")

            # Generate reports
            try:
                print("\n   Generating reports...")

                # Console report
                self.reporter.print_console_report(self.results)

                # HTML report
                self.reporter.generate_html_report(
                    self.results,
                    output_file="biasclean_results/biasclean_report.html"
                )

            except Exception as e:
                print(f"   Report generation failed: {str(e)}")

            # ================================================================
            # FINAL SUCCESS MESSAGE
            # ================================================================
            print(f"\n{'='*80}")
            print("PIPELINE COMPLETED SUCCESSFULLY!")
            print(f"{'='*80}")
            print(f"   Results saved to: biasclean_results/")
            print(f"   Visualizations: disparity_comparison.png, fairness_improvements.png")
            print(f"   Reports: biasclean_report.html, pipeline_summary.json")
            print(f"   Corrected dataset: corrected_dataset.csv")
            print(f"{'='*80}\n")

            return self.results

        except Exception as e:
            print(f"\n{'='*80}")
            print(f"PIPELINE FAILED")
            print(f"{'='*80}")
            print(f"Error: {str(e)}")
            print(f"{'='*80}\n")
            raise

    def _run_statistical_diagnosis(self, feature_map: Dict, target_column: str) -> Dict:
        """Run comprehensive statistical tests for bias detection with WEIGHT-ADJUSTED SIGNIFICANCE"""
        diagnostic_results = {
            "feature_tests": {},
            "significant_bias_count": 0,
            "requires_mitigation": False,
            "target_column_used": target_column
        }

        # FIXED: Calculate min p-value threshold based on domain max weight
        max_weight = max(self.config["weights"].values()) if self.config["weights"] else 0.25
        min_p_threshold = 0.05  # Minimum threshold for highest weight features
        max_p_threshold = 0.15  # Maximum threshold for lowest weight features

        for feature, column in feature_map.items():
            try:
                # Create contingency table
                contingency = pd.crosstab(
                    self.original_df[column],
                    self.original_df[target_column]
                )

                # Choose appropriate test
                if contingency.shape == (2, 2):
                    _, p_value = fisher_exact(contingency)
                    test_used = "fisher-exact"
                else:
                    chi2, p_value, _, _ = chi2_contingency(contingency)
                    test_used = "chi-square"

                # FIXED: Weight-adjusted significance threshold
                # Higher weight = LOWER threshold (more sensitive detection)
                weight = self.config["weights"].get(feature, 0.05)

                # Calculate dynamic threshold based on weight
                # Higher weight features get lower thresholds (more sensitive)
                weight_factor = weight / max_weight  # Normalize to [0, 1]
                p_threshold = min_p_threshold + (weight_factor * (max_p_threshold - min_p_threshold))
                p_threshold = max(min_p_threshold, min(max_p_threshold, p_threshold))

                # Determine significance using weight-adjusted threshold
                significant = p_value < p_threshold

                diagnostic_results["feature_tests"][feature] = {
                    "p_value": p_value,
                    "significant_bias": significant,
                    "test_used": test_used,
                    "column_name": column,
                    "weight_used": weight,
                    "threshold_used": p_threshold  # Store threshold for display
                }

                if significant:
                    diagnostic_results["significant_bias_count"] += 1

            except Exception as e:
                diagnostic_results["feature_tests"][feature] = {
                    "error": str(e),
                    "significant_bias": False,
                    "test_used": "failed"
                }

        # Calculate overall bias score
        diagnostic_results["initial_bias_score"] = self.engine.score(
            self.original_df, target_column
        )

        # Determine if mitigation is needed
        diagnostic_results["requires_mitigation"] = (
            diagnostic_results["significant_bias_count"] > 0 and
            diagnostic_results["initial_bias_score"] > 0.05
        )

        return diagnostic_results

    def _save_results(self):
        """Save all pipeline results to disk"""
        os.makedirs("biasclean_results", exist_ok=True)

        # Save corrected dataset
        if self.corrected_df is not None:
            self.corrected_df.to_csv("biasclean_results/corrected_dataset.csv", index=False)

        # Save feature mappings
        with open("biasclean_results/feature_mappings.json", "w") as f:
            json.dump(self.approved_mappings, f, indent=2, default=str)

        # Save pipeline summary
        summary = {
            "timestamp": datetime.now().isoformat(),
            "domain": self.domain,
            "jurisdiction": self.jurisdiction,
            "dataset_info": {
                "original_records": len(self.original_df),
                "corrected_records": len(self.corrected_df) if self.corrected_df is not None else len(self.original_df),
                "columns": len(self.original_df.columns),
                "target_column": self.results.get("target_column")
            },
            "analysis_results": {
                "features_analyzed": list(self.results.get("feature_map", {}).keys()),
                "significant_biases": self.results.get("diagnostics", {}).get("significant_bias_count", 0),
                "initial_bias_score": self.results.get("diagnostics", {}).get("initial_bias_score", 0),
                "final_bias_score": self.results.get("diagnostics", {}).get("final_bias_score", 0)
            },
            "fairness_improvements": self.results.get("validation", {}).get("fairness_improvement", {}),
            "data_integrity": self.results.get("validation", {}).get("data_integrity", {})
        }

        with open("biasclean_results/pipeline_summary.json", "w") as f:
            json.dump(summary, f, indent=2, default=str)

        print(f"   Results saved to biasclean_results/")

# ============================================================================
# 8. SAMPLE DATASET GENERATOR (For Testing - 7 DOMAINS)
# ============================================================================

def create_sample_justice_dataset(n_samples: int = 2000, seed: int = 42) -> pd.DataFrame:
    """Create realistic justice dataset with inherent bias for testing"""
    np.random.seed(seed)

    print(f"\n{'='*80}")
    print(f"GENERATING SAMPLE JUSTICE DATASET")
    print(f"{'='*80}")
    print(f"   Records: {n_samples:,}")
    print(f"   Seed: {seed}")

    # Generate base demographics
    data = {
        "person_id": range(n_samples),
        "defendant_name": [f"Defendant_{i}" for i in range(n_samples)],
        "race": np.random.choice(
            ["White", "Black", "Hispanic", "Asian", "Other"],
            n_samples,
            p=[0.50, 0.30, 0.15, 0.04, 0.01]
        ),
        "age": np.random.randint(18, 75, n_samples),
        "sex": np.random.choice(["Male", "Female"], n_samples, p=[0.70, 0.30]),
        "priors_count": np.random.randint(0, 25, n_samples),
        "c_charge_desc": np.random.choice(
            ["Aggravated Assault", "Burglary", "Drug Possession", "Theft", "Battery", "Fraud"],
            n_samples
        ),
        "screening_date": pd.date_range("2020-01-01", periods=n_samples, freq="H")
    }

    df = pd.DataFrame(data)

    # Create biased recidivism outcome
    base_rate = 0.35
    race_biases = {
        "White": base_rate * 1.50,
        "Black": base_rate * 0.30,
        "Hispanic": base_rate * 1.15,
        "Asian": base_rate * 0.70,
        "Other": base_rate * 1.00
    }

    def age_factor(age):
        if age < 25: return 1.30
        elif age < 40: return 1.00
        elif age < 60: return 0.85
        else: return 0.70

    def priors_factor(priors):
        if priors == 0: return 0.60
        elif priors < 3: return 0.90
        elif priors < 6: return 1.10
        else: return 1.40

    recidivism = []
    for idx, row in df.iterrows():
        prob = race_biases[row["race"]]
        prob *= age_factor(row["age"])
        prob *= priors_factor(row["priors_count"])
        prob *= np.random.uniform(0.90, 1.10)
        prob = np.clip(prob, 0.05, 0.95)
        recidivism.append(np.random.binomial(1, prob))

    df["two_year_recid"] = recidivism

    print(f"\n   Recidivism Rates by Race (Showing Bias):")
    recid_by_race = df.groupby("race")["two_year_recid"].mean().sort_values(ascending=False)
    for race, rate in recid_by_race.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {race:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Overall Recidivism Rate: {df['two_year_recid'].mean():.1%}")
    print(f"   Max Disparity: {recid_by_race.max() - recid_by_race.min():.1%}")
    print(f"{'='*80}\n")

    return df

def create_sample_health_dataset(n_samples: int = 2000, seed: int = 42) -> pd.DataFrame:
    """Create realistic healthcare dataset with inherent bias for testing"""
    np.random.seed(seed)

    print(f"\n{'='*80}")
    print(f"GENERATING SAMPLE HEALTHCARE DATASET")
    print(f"{'='*80}")
    print(f"   Records: {n_samples:,}")
    print(f"   Seed: {seed}")

    data = {
        "patient_id": range(n_samples),
        "patient_name": [f"Patient_{i}" for i in range(n_samples)],
        "ethnicity": np.random.choice(
            ["White", "Black", "Asian", "Other"],
            n_samples,
            p=[0.75, 0.15, 0.07, 0.03]
        ),
        "age": np.random.randint(18, 90, n_samples),
        "gender": np.random.choice(["Male", "Female"], n_samples, p=[0.48, 0.52]),
        "postcode": np.random.choice(["Urban", "Rural", "Suburban"], n_samples),
        "bmi": np.random.normal(26, 5, n_samples).clip(18, 45),
        "smoking_status": np.random.choice(["Never", "Former", "Current"], n_samples, p=[0.50, 0.30, 0.20]),
        "family_history": np.random.binomial(1, 0.25, n_samples),
        "socioeconomic_score": np.random.randint(1, 10, n_samples),
        "visit_date": pd.date_range("2022-01-01", periods=n_samples, freq="H")
    }

    df = pd.DataFrame(data)

    base_rate = 0.20
    ethnic_biases = {
        "White": base_rate * 1.50,
        "Black": base_rate * 0.30,
        "Asian": base_rate * 0.95,
        "Other": base_rate * 1.10
    }

    def bmi_factor(bmi):
        if bmi < 18.5: return 0.90
        elif bmi < 25: return 0.85
        elif bmi < 30: return 1.10
        else: return 1.40

    def smoking_factor(status):
        if status == "Never": return 0.80
        elif status == "Former": return 1.10
        else: return 1.50

    diagnoses = []
    for idx, row in df.iterrows():
        prob = ethnic_biases[row["ethnicity"]]
        prob *= bmi_factor(row["bmi"])
        prob *= smoking_factor(row["smoking_status"])
        prob *= (1 + (row["family_history"] * 0.3))
        prob *= np.random.uniform(0.90, 1.10)
        prob = np.clip(prob, 0.05, 0.80)
        diagnoses.append(np.random.binomial(1, prob))

    df["diagnosis_positive"] = diagnoses

    print(f"\n   Diagnosis Rates by Ethnicity (Showing Bias):")
    diagnosis_by_ethnicity = df.groupby("ethnicity")["diagnosis_positive"].mean().sort_values(ascending=False)
    for ethnicity, rate in diagnosis_by_ethnicity.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {ethnicity:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Overall Diagnosis Rate: {df['diagnosis_positive'].mean():.1%}")
    print(f"   Max Disparity: {diagnosis_by_ethnicity.max() - diagnosis_by_ethnicity.min():.1%}")
    print(f"{'='*80}\n")

    return df

def create_sample_finance_dataset(n_samples: int = 2000, seed: int = 42) -> pd.DataFrame:
    """Create realistic finance dataset with inherent bias for testing"""
    np.random.seed(seed)

    print(f"\n{'='*80}")
    print(f"GENERATING SAMPLE FINANCE DATASET")
    print(f"{'='*80}")
    print(f"   Records: {n_samples:,}")
    print(f"   Seed: {seed}")

    data = {
        "applicant_id": range(n_samples),
        "applicant_name": [f"Applicant_{i}" for i in range(n_samples)],
        "ethnicity": np.random.choice(
            ["White", "Black", "Asian", "Other"],
            n_samples,
            p=[0.70, 0.15, 0.10, 0.05]
        ),
        "age": np.random.randint(20, 70, n_samples),
        "gender": np.random.choice(["Male", "Female"], n_samples, p=[0.55, 0.45]),
        "postcode": np.random.choice(["Urban", "Rural", "Suburban"], n_samples),
        "annual_income": np.random.normal(50000, 20000, n_samples).clip(20000, 150000),
        "credit_score": np.random.randint(300, 850, n_samples),
        "debt_to_income": np.random.uniform(0.1, 0.8, n_samples),
        "employment_years": np.random.randint(0, 40, n_samples),
        "application_date": pd.date_range("2023-01-01", periods=n_samples, freq="H")
    }

    df = pd.DataFrame(data)

    base_rate = 0.65
    ethnic_biases = {
        "White": base_rate * 1.50,
        "Black": base_rate * 0.30,
        "Asian": base_rate * 0.95,
        "Other": base_rate * 0.85
    }

    def credit_factor(score):
        if score < 500: return 0.40
        elif score < 600: return 0.70
        elif score < 700: return 0.90
        elif score < 750: return 1.10
        else: return 1.30

    def dti_factor(dti):
        if dti < 0.3: return 1.20
        elif dti < 0.5: return 1.00
        elif dti < 0.7: return 0.80
        else: return 0.60

    approvals = []
    for idx, row in df.iterrows():
        prob = ethnic_biases[row["ethnicity"]]
        prob *= credit_factor(row["credit_score"])
        prob *= dti_factor(row["debt_to_income"])
        prob *= np.random.uniform(0.95, 1.05)
        prob = np.clip(prob, 0.05, 0.95)
        approvals.append(np.random.binomial(1, prob))

    df["loan_approved"] = approvals

    print(f"\n   Loan Approval Rates by Ethnicity (Showing Bias):")
    approval_by_ethnicity = df.groupby("ethnicity")["loan_approved"].mean().sort_values(ascending=False)
    for ethnicity, rate in approval_by_ethnicity.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {ethnicity:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Overall Approval Rate: {df['loan_approved'].mean():.1%}")
    print(f"   Max Disparity: {approval_by_ethnicity.max() - approval_by_ethnicity.min():.1%}")
    print(f"{'='*80}\n")

    return df

def create_sample_hiring_dataset(n_samples: int = 2000, seed: int = 42) -> pd.DataFrame:
    """Create realistic hiring dataset with inherent bias for testing"""
    np.random.seed(seed)

    print(f"\n{'='*80}")
    print(f"GENERATING SAMPLE HIRING DATASET")
    print(f"{'='*80}")
    print(f"   Records: {n_samples:,}")
    print(f"   Seed: {seed}")

    data = {
        "candidate_id": range(n_samples),
        "candidate_name": [f"Candidate_{i}" for i in range(n_samples)],
        "ethnicity": np.random.choice(
            ["White", "Black", "Asian", "Other"],
            n_samples,
            p=[0.65, 0.20, 0.10, 0.05]
        ),
        "age": np.random.randint(20, 65, n_samples),
        "gender": np.random.choice(["Male", "Female"], n_samples, p=[0.60, 0.40]),
        "postcode": np.random.choice(["Urban", "Rural", "Suburban"], n_samples),
        "education_years": np.random.randint(10, 22, n_samples),
        "years_experience": np.random.randint(0, 30, n_samples),
        "resume_score": np.random.randint(50, 100, n_samples),
        "interview_score": np.random.randint(40, 100, n_samples),
        "skill_match_percent": np.random.uniform(0.5, 1.0, n_samples),
        "application_date": pd.date_range("2023-01-01", periods=n_samples, freq="H"),
        "disability_status": np.random.choice(["None", "Physical", "Cognitive", "Sensory"],
                                            n_samples, p=[0.85, 0.08, 0.05, 0.02]),
        "migration_status": np.random.choice(["Citizen", "Permanent Resident", "Work Visa", "Other"],
                                           n_samples, p=[0.70, 0.15, 0.10, 0.05])
    }

    df = pd.DataFrame(data)

    base_rate = 0.40
    ethnic_biases = {
        "White": base_rate * 1.50,
        "Black": base_rate * 0.30,
        "Asian": base_rate * 0.90,
        "Other": base_rate * 0.75
    }

    gender_biases = {
        "Male": base_rate * 1.15,
        "Female": base_rate * 0.85
    }

    def experience_factor(years):
        if years < 2: return 0.70
        elif years < 5: return 0.90
        elif years < 10: return 1.10
        elif years < 15: return 1.25
        else: return 1.15

    def education_factor(years):
        if years < 12: return 0.80
        elif years < 16: return 1.00
        elif years < 18: return 1.15
        else: return 1.25

    def disability_factor(status):
        if status == "None": return 1.00
        else: return 0.80

    hiring_decisions = []
    for idx, row in df.iterrows():
        prob = ethnic_biases[row["ethnicity"]]
        prob *= gender_biases[row["gender"]]
        prob *= experience_factor(row["years_experience"])
        prob *= education_factor(row["education_years"])
        prob *= disability_factor(row["disability_status"])
        prob *= (0.5 + (row["skill_match_percent"] * 0.5))
        prob *= np.random.uniform(0.95, 1.05)
        prob = np.clip(prob, 0.05, 0.95)
        hiring_decisions.append(np.random.binomial(1, prob))

    df["hired"] = hiring_decisions

    print(f"\n   Hiring Rates by Ethnicity (Showing Bias):")
    hiring_by_ethnicity = df.groupby("ethnicity")["hired"].mean().sort_values(ascending=False)
    for ethnicity, rate in hiring_by_ethnicity.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {ethnicity:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Hiring Rates by Gender:")
    hiring_by_gender = df.groupby("gender")["hired"].mean().sort_values(ascending=False)
    for gender, rate in hiring_by_gender.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {gender:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Overall Hiring Rate: {df['hired'].mean():.1%}")
    print(f"   Max Ethnicity Disparity: {hiring_by_ethnicity.max() - hiring_by_ethnicity.min():.1%}")
    print(f"   Gender Disparity: {hiring_by_gender.max() - hiring_by_gender.min():.1%}")
    print(f"{'='*80}\n")

    return df

def create_sample_education_dataset(n_samples: int = 2000, seed: int = 42) -> pd.DataFrame:
    """Create realistic education dataset with inherent bias for testing"""
    np.random.seed(seed)

    print(f"\n{'='*80}")
    print(f"GENERATING SAMPLE EDUCATION DATASET")
    print(f"{'='*80}")
    print(f"   Records: {n_samples:,}")
    print(f"   Seed: {seed}")

    data = {
        "student_id": range(n_samples),
        "student_name": [f"Student_{i}" for i in range(n_samples)],
        "ethnicity": np.random.choice(
            ["White", "Black", "Asian", "Other"],
            n_samples,
            p=[0.70, 0.15, 0.10, 0.05]
        ),
        "age": np.random.randint(16, 25, n_samples),
        "gender": np.random.choice(["Male", "Female"], n_samples, p=[0.48, 0.52]),
        "postcode": np.random.choice(["Affluent", "Average", "Disadvantaged"], n_samples, p=[0.30, 0.50, 0.20]),
        "parent_income": np.random.normal(50000, 25000, n_samples).clip(15000, 150000),
        "previous_grades": np.random.uniform(50, 95, n_samples),
        "attendance_rate": np.random.uniform(0.70, 1.0, n_samples),
        "test_score": np.random.normal(100, 15, n_samples).clip(60, 140),
        "special_needs": np.random.choice(["None", "Mild", "Moderate", "Severe"], n_samples, p=[0.80, 0.12, 0.06, 0.02]),
        "english_additional": np.random.choice(["Native", "Additional"], n_samples, p=[0.85, 0.15]),
        "application_date": pd.date_range("2023-09-01", periods=n_samples, freq="H")
    }

    df = pd.DataFrame(data)

    base_rate = 0.45
    ethnic_biases = {
        "White": base_rate * 1.50,
        "Black": base_rate * 0.30,
        "Asian": base_rate * 1.10,
        "Other": base_rate * 0.80
    }

    def income_factor(income): return 1.0
    def test_factor(score): return 1.0
    def needs_factor(needs): return 1.0

    admissions = []
    for idx, row in df.iterrows():
        prob = ethnic_biases[row["ethnicity"]]
        prob *= income_factor(row["parent_income"])
        prob *= test_factor(row["test_score"])
        prob *= needs_factor(row["special_needs"])
        if row["english_additional"] == "Additional": prob *= 0.85
        prob *= (0.7 + (row["attendance_rate"] * 0.3))
        prob *= np.random.uniform(0.95, 1.05)
        prob = np.clip(prob, 0.05, 0.95)
        admissions.append(np.random.binomial(1, prob))

    df["university_admitted"] = admissions

    print(f"\n   University Admission Rates by Ethnicity (Showing Bias):")
    admission_by_ethnicity = df.groupby("ethnicity")["university_admitted"].mean().sort_values(ascending=False)
    for ethnicity, rate in admission_by_ethnicity.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {ethnicity:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Admission Rates by Special Needs Status:")
    admission_by_needs = df.groupby("special_needs")["university_admitted"].mean().sort_values(ascending=False)
    for needs, rate in admission_by_needs.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {needs:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Overall Admission Rate: {df['university_admitted'].mean():.1%}")
    print(f"   Max Ethnicity Disparity: {admission_by_ethnicity.max() - admission_by_ethnicity.min():.1%}")
    print(f"   Special Needs Disparity: {admission_by_needs.max() - admission_by_needs.min():.1%}")
    print(f"{'='*80}\n")

    return df

def create_sample_business_dataset(n_samples: int = 2000, seed: int = 42) -> pd.DataFrame:
    """Create realistic business funding dataset with inherent bias for testing"""
    np.random.seed(seed)

    print(f"\n{'='*80}")
    print(f"GENERATING SAMPLE BUSINESS DATASET")
    print(f"{'='*80}")
    print(f"   Records: {n_samples:,}")
    print(f"   Seed: {seed}")

    # Generate base business demographics
    data = {
        "business_id": range(n_samples),
        "business_name": [f"Company_{i}" for i in range(n_samples)],
        "owner_ethnicity": np.random.choice(
            ["White", "Black", "Asian", "Other"],
            n_samples,
            p=[0.60, 0.20, 0.15, 0.05]
        ),
        "owner_gender": np.random.choice(["Male", "Female", "Non-binary"], n_samples, p=[0.65, 0.30, 0.05]),
        "business_age": np.random.randint(0, 50, n_samples),
        "region": np.random.choice(["London", "Manchester", "Birmingham", "Glasgow", "Cardiff"],
                                 size=n_samples, p=[0.40, 0.20, 0.15, 0.15, 0.10]),
        "sector": np.random.choice(["Tech", "Manufacturing", "Retail", "Services", "Construction"],
                                 size=n_samples),
        "revenue": np.random.exponential(scale=500000, size=n_samples).astype(int),
        "employees": np.random.randint(1, 500, size=n_samples),
        "profit_margin": np.random.uniform(-0.1, 0.3, n_samples),
        "assets": np.random.exponential(scale=1000000, size=n_samples).astype(int),
        "disability_friendly": np.random.choice(["Yes", "No"], n_samples, p=[0.20, 0.80]),
        "international_operations": np.random.choice(["Yes", "No"], n_samples, p=[0.30, 0.70]),
        "application_date": pd.date_range("2023-01-01", periods=n_samples, freq="H")
    }

    df = pd.DataFrame(data)

    # Create biased funding outcome
    # Base rate: 35%
    base_rate = 0.35

    # Ethnicity-based bias
    ethnic_biases = {
        "White": base_rate * 1.50,     # 53% funding (50% higher)
        "Black": base_rate * 0.30,     # 11% funding (70% lower) - SIGNIFICANT BIAS
        "Asian": base_rate * 0.90,     # 32% funding (10% lower)
        "Other": base_rate * 0.80      # 28% funding (20% lower)
    }

    # Gender-based bias
    gender_biases = {
        "Male": base_rate * 1.20,      # 42% funding (20% higher)
        "Female": base_rate * 0.85,    # 30% funding (15% lower)
        "Non-binary": base_rate * 0.70 # 25% funding (30% lower)
    }

    # Revenue factor
    def revenue_factor(revenue):
        if revenue < 100000: return 0.70
        elif revenue < 500000: return 0.90
        elif revenue < 1000000: return 1.10
        elif revenue < 5000000: return 1.30
        else: return 1.50

    # Employees factor
    def employees_factor(employees):
        if employees < 10: return 0.80
        elif employees < 50: return 0.95
        elif employees < 100: return 1.10
        elif employees < 250: return 1.25
        else: return 1.40

    # Profit margin factor
    def profit_factor(margin):
        if margin < 0: return 0.60
        elif margin < 0.05: return 0.85
        elif margin < 0.10: return 1.00
        elif margin < 0.15: return 1.15
        elif margin < 0.20: return 1.30
        else: return 1.50

    # Region factor
    def region_factor(region):
        if region == "London": return 1.30
        elif region == "Manchester": return 1.10
        elif region == "Birmingham": return 1.00
        elif region == "Glasgow": return 0.90
        else: return 0.85  # Cardiff

    # Generate funding decision with compound biases
    funding_decisions = []
    funding_amounts = []
    for idx, row in df.iterrows():
        prob = ethnic_biases[row["owner_ethnicity"]]
        prob *= gender_biases[row["owner_gender"]]
        prob *= revenue_factor(row["revenue"])
        prob *= employees_factor(row["employees"])
        prob *= profit_factor(row["profit_margin"])
        prob *= region_factor(row["region"])

        # Disability friendly bonus
        if row["disability_friendly"] == "Yes":
            prob *= 1.10

        # International operations bonus
        if row["international_operations"] == "Yes":
            prob *= 1.15

        # Business age factor
        if row["business_age"] < 3:
            prob *= 0.80  # New businesses face more scrutiny
        elif row["business_age"] < 10:
            prob *= 1.00
        else:
            prob *= 1.20  # Established businesses get preference

        # Add noise
        prob *= np.random.uniform(0.95, 1.05)

        # Clip to valid probability range
        prob = np.clip(prob, 0.05, 0.95)

        # Generate binary outcome
        funded = np.random.binomial(1, prob)
        funding_decisions.append(funded)

        # Generate funding amount if approved
        if funded:
            # Base amount + factors
            base_amount = 50000
            amount = base_amount * (row["revenue"] / 1000000)  # Scale with revenue
            amount *= (row["employees"] / 50)  # Scale with employees
            amount *= profit_factor(row["profit_margin"])
            amount = np.clip(amount, 10000, 500000)
            amount = int(amount * np.random.uniform(0.8, 1.2))  # Add noise
            funding_amounts.append(amount)
        else:
            funding_amounts.append(0)

    df["funding_approved"] = funding_decisions
    df["funding_amount"] = funding_amounts

    # Print bias statistics
    print(f"\n   Funding Approval Rates by Owner Ethnicity (Showing Bias):")
    funding_by_ethnicity = df.groupby("owner_ethnicity")["funding_approved"].mean().sort_values(ascending=False)
    for ethnicity, rate in funding_by_ethnicity.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {ethnicity:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Funding Approval Rates by Owner Gender:")
    funding_by_gender = df.groupby("owner_gender")["funding_approved"].mean().sort_values(ascending=False)
    for gender, rate in funding_by_gender.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {gender:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Funding by Region:")
    funding_by_region = df.groupby("region")["funding_approved"].mean().sort_values(ascending=False)
    for region, rate in funding_by_region.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {region:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Overall Funding Rate: {df['funding_approved'].mean():.1%}")
    print(f"   Ethnicity Disparity: {funding_by_ethnicity.max() - funding_by_ethnicity.min():.1%}")
    print(f"   Gender Disparity: {funding_by_gender.max() - funding_by_gender.min():.1%}")
    print(f"   Region Disparity: {funding_by_region.max() - funding_by_region.min():.1%}")

    # Calculate average funding amount
    avg_funding = df[df["funding_approved"] == 1]["funding_amount"].mean() if df["funding_approved"].sum() > 0 else 0
    print(f"   Average Funding Amount: £{avg_funding:,.0f}")

    print(f"{'='*80}\n")

    return df

def create_sample_governance_dataset(n_samples: int = 2000, seed: int = 42) -> pd.DataFrame:
    """Create realistic governance election/appointment dataset with inherent bias for testing"""
    np.random.seed(seed)

    print(f"\n{'='*80}")
    print(f"GENERATING SAMPLE GOVERNANCE DATASET")
    print(f"{'='*80}")
    print(f"   Records: {n_samples:,}")
    print(f"   Seed: {seed}")

    # Generate base governance demographics
    data = {
        "candidate_id": range(n_samples),
        "candidate_name": [f"Candidate_{i}" for i in range(n_samples)],
        "ethnicity": np.random.choice(
            ["White", "Black", "Asian", "Other"],
            n_samples,
            p=[0.75, 0.15, 0.07, 0.03]
        ),
        "gender": np.random.choice(["Male", "Female"], n_samples, p=[0.65, 0.35]),
        "age": np.random.randint(25, 75, n_samples),
        "region": np.random.choice(["London", "South East", "North West", "Midlands", "Scotland", "Wales"],
                                 size=n_samples, p=[0.25, 0.20, 0.18, 0.15, 0.12, 0.10]),
        "constituency_type": np.random.choice(["Urban", "Suburban", "Rural", "Mixed"], n_samples),
        "education_level": np.random.choice(["High School", "Undergraduate", "Postgraduate", "Professional"],
                                          n_samples, p=[0.20, 0.40, 0.30, 0.10]),
        "political_experience_years": np.random.randint(0, 40, n_samples),
        "campaign_budget": np.random.exponential(scale=50000, size=n_samples).astype(int),
        "endorsement_count": np.random.randint(0, 50, n_samples),
        "disability_status": np.random.choice(["None", "Physical", "Sensory", "Cognitive"],
                                            n_samples, p=[0.85, 0.08, 0.05, 0.02]),
        "citizenship_status": np.random.choice(["UK Citizen", "Dual Citizen", "Naturalized", "Other"],
                                             n_samples, p=[0.70, 0.15, 0.10, 0.05]),
        "socioeconomic_background": np.random.choice(["Working Class", "Middle Class", "Upper Middle", "Affluent"],
                                                    n_samples, p=[0.35, 0.45, 0.15, 0.05]),
        "previous_public_office": np.random.choice(["None", "Local Council", "MP", "Minister", "Other"],
                                                  n_samples, p=[0.50, 0.30, 0.10, 0.05, 0.05]),
        "policy_experience_score": np.random.randint(30, 100, n_samples),
        "campaign_start_date": pd.date_range("2023-01-01", periods=n_samples, freq="H"),
        "media_coverage_score": np.random.uniform(0.1, 1.0, n_samples)
    }

    df = pd.DataFrame(data)

    # Create biased election outcome
    # Base rate: 40%
    base_rate = 0.40

    # Ethnicity-based bias
    ethnic_biases = {
        "White": base_rate * 1.60,     # 64% election (60% higher)
        "Black": base_rate * 0.40,     # 16% election (60% lower) - SIGNIFICANT BIAS
        "Asian": base_rate * 0.80,     # 32% election (20% lower)
        "Other": base_rate * 0.70      # 28% election (30% lower)
    }

    # Gender-based bias
    gender_biases = {
        "Male": base_rate * 1.30,      # 52% election (30% higher)
        "Female": base_rate * 0.75     # 30% election (25% lower)
    }

    # Region factor
    def region_factor(region):
        if region == "London": return 1.40
        elif region == "South East": return 1.25
        elif region == "North West": return 1.00
        elif region == "Midlands": return 0.95
        elif region == "Scotland": return 0.90
        else: return 0.85  # Wales

    # Age factor (discrimination against very young and very old)
    def age_factor(age):
        if age < 30: return 0.70
        elif age < 40: return 0.90
        elif age < 50: return 1.10
        elif age < 60: return 1.20
        elif age < 70: return 0.95
        else: return 0.80

    # Campaign budget factor
    def budget_factor(budget):
        if budget < 10000: return 0.60
        elif budget < 25000: return 0.80
        elif budget < 50000: return 1.00
        elif budget < 100000: return 1.30
        else: return 1.60

    # Experience factor
    def experience_factor(years):
        if years < 2: return 0.70
        elif years < 5: return 0.85
        elif years < 10: return 1.00
        elif years < 15: return 1.20
        elif years < 20: return 1.35
        else: return 1.25

    # Education factor
    def education_factor(education):
        if education == "High School": return 0.70
        elif education == "Undergraduate": return 0.95
        elif education == "Postgraduate": return 1.15
        else: return 1.30  # Professional

    # Disability factor
    def disability_factor(status):
        if status == "None": return 1.00
        else: return 0.75

    # Citizenship factor
    def citizenship_factor(status):
        if status == "UK Citizen": return 1.00
        elif status == "Dual Citizen": return 0.95
        elif status == "Naturalized": return 0.90
        else: return 0.70

    # Generate election outcome with compound biases
    election_outcomes = []
    vote_shares = []
    for idx, row in df.iterrows():
        prob = ethnic_biases[row["ethnicity"]]
        prob *= gender_biases[row["gender"]]
        prob *= age_factor(row["age"])
        prob *= region_factor(row["region"])
        prob *= budget_factor(row["campaign_budget"])
        prob *= experience_factor(row["political_experience_years"])
        prob *= education_factor(row["education_level"])
        prob *= disability_factor(row["disability_status"])
        prob *= citizenship_factor(row["citizenship_status"])

        # Socioeconomic background factor
        if row["socioeconomic_background"] == "Affluent":
            prob *= 1.25
        elif row["socioeconomic_background"] == "Upper Middle":
            prob *= 1.15
        elif row["socioeconomic_background"] == "Middle Class":
            prob *= 1.00
        else:  # Working Class
            prob *= 0.85

        # Previous public office factor
        if row["previous_public_office"] == "Minister":
            prob *= 1.40
        elif row["previous_public_office"] == "MP":
            prob *= 1.25
        elif row["previous_public_office"] == "Local Council":
            prob *= 1.10

        # Policy experience bonus
        prob *= (0.5 + (row["policy_experience_score"] / 100) * 0.5)

        # Media coverage bonus
        prob *= (0.7 + row["media_coverage_score"] * 0.3)

        # Endorsement bonus
        prob *= (1.0 + (row["endorsement_count"] * 0.02))

        # Add noise
        prob *= np.random.uniform(0.95, 1.05)

        # Clip to valid probability range
        prob = np.clip(prob, 0.05, 0.95)

        # Generate binary outcome
        elected = np.random.binomial(1, prob)
        election_outcomes.append(elected)

        # Generate simulated vote share if elected
        if elected:
            vote_share = 0.45 + (prob * 0.3) + np.random.uniform(-0.1, 0.1)
            vote_share = np.clip(vote_share, 0.35, 0.65)
            vote_shares.append(vote_share)
        else:
            vote_shares.append(0.0)

    df["elected"] = election_outcomes
    df["vote_share"] = vote_shares

    # Print bias statistics
    print(f"\n   Election Rates by Ethnicity (Showing Bias):")
    election_by_ethnicity = df.groupby("ethnicity")["elected"].mean().sort_values(ascending=False)
    for ethnicity, rate in election_by_ethnicity.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {ethnicity:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Election Rates by Gender:")
    election_by_gender = df.groupby("gender")["elected"].mean().sort_values(ascending=False)
    for gender, rate in election_by_gender.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {gender:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Election by Region:")
    election_by_region = df.groupby("region")["elected"].mean().sort_values(ascending=False)
    for region, rate in election_by_region.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {region:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Election by Age Group:")
    df["age_group"] = pd.cut(df["age"], bins=[25, 35, 45, 55, 65, 75],
                           labels=["25-34", "35-44", "45-54", "55-64", "65-74"])
    election_by_age = df.groupby("age_group")["elected"].mean().sort_values(ascending=False)
    for age_group, rate in election_by_age.items():
        deviation = ((rate - base_rate) / base_rate) * 100
        print(f"     • {age_group:15} {rate:.1%}  (deviation: {deviation:+.0f}%)")

    print(f"\n   Overall Election Rate: {df['elected'].mean():.1%}")
    print(f"   Ethnicity Disparity: {election_by_ethnicity.max() - election_by_ethnicity.min():.1%}")
    print(f"   Gender Disparity: {election_by_gender.max() - election_by_gender.min():.1%}")
    print(f"   Region Disparity: {election_by_region.max() - election_by_region.min():.1%}")
    print(f"   Age Disparity: {election_by_age.max() - election_by_age.min():.1%}")

    # Calculate average vote share for elected candidates
    avg_vote_share = df[df["elected"] == 1]["vote_share"].mean() if df["elected"].sum() > 0 else 0
    print(f"   Average Vote Share (elected): {avg_vote_share:.1%}")

    print(f"{'='*80}\n")

    return df

# ============================================================================
# 9. INTERACTIVE COLAB INTERFACE (7 DOMAINS)
# ============================================================================

def run_interactive_pipeline():
    """Interactive interface for Colab users"""
    try:
        from google.colab import files
        import io
        colab_available = True
    except ImportError:
        colab_available = False
        print("Note: Google Colab not available. Running in local mode.")

    print(f"\n{'='*80}")
    print("UNIVERSAL BIASCLEAN - INTERACTIVE MODE")
    print(f"{'='*80}\n")

    print("Choose data source:")
    print("  1. Upload your own CSV file")
    print("  2. Generate sample justice dataset")
    print("  3. Generate sample healthcare dataset")
    print("  4. Generate sample finance dataset")
    print("  5. Generate sample hiring dataset")
    print("  6. Generate sample education dataset")
    print("  7. Generate sample business dataset")
    print("  8. Generate sample governance dataset")
    print()

    choice = input("Enter choice (1-8): ").strip()

    df = None
    file_name = None

    if choice == "1":
        if colab_available:
            print("\nPlease upload your CSV file...")
            uploaded = files.upload()

            if not uploaded:
                print("No file uploaded. Exiting.")
                return None

            file_name = list(uploaded.keys())[0]
            df = pd.read_csv(io.BytesIO(uploaded[file_name]))
        else:
            file_path = input("\nEnter path to CSV file: ").strip()
            if not os.path.exists(file_path):
                print(f"File not found: {file_path}")
                return None
            df = pd.read_csv(file_path)
            file_name = os.path.basename(file_path)

        print(f"\nLoaded: {file_name}")
        print(f"   Records: {len(df):,}")
        print(f"   Columns: {len(df.columns)}")

        # Show column preview
        print(f"\n   Columns: {', '.join(df.columns[:10])}")
        if len(df.columns) > 10:
            print(f"   ... and {len(df.columns) - 10} more")

    elif choice == "2":
        n_samples = input("\nEnter number of samples (default: 2000): ").strip()
        n_samples = int(n_samples) if n_samples else 2000
        df = create_sample_justice_dataset(n_samples=n_samples)
        file_name = "sample_justice_data.csv"

    elif choice == "3":
        n_samples = input("\nEnter number of samples (default: 2000): ").strip()
        n_samples = int(n_samples) if n_samples else 2000
        df = create_sample_health_dataset(n_samples=n_samples)
        file_name = "sample_health_data.csv"

    elif choice == "4":
        n_samples = input("\nEnter number of samples (default: 2000): ").strip()
        n_samples = int(n_samples) if n_samples else 2000
        df = create_sample_finance_dataset(n_samples=n_samples)
        file_name = "sample_finance_data.csv"

    elif choice == "5":
        n_samples = input("\nEnter number of samples (default: 2000): ").strip()
        n_samples = int(n_samples) if n_samples else 2000
        df = create_sample_hiring_dataset(n_samples=n_samples)
        file_name = "sample_hiring_data.csv"

    elif choice == "6":
        n_samples = input("\nEnter number of samples (default: 2000): ").strip()
        n_samples = int(n_samples) if n_samples else 2000
        df = create_sample_education_dataset(n_samples=n_samples)
        file_name = "sample_education_data.csv"

    elif choice == "7":
        n_samples = input("\nEnter number of samples (default: 2000): ").strip()
        n_samples = int(n_samples) if n_samples else 2000
        df = create_sample_business_dataset(n_samples=n_samples)
        file_name = "sample_business_data.csv"

    elif choice == "8":
        n_samples = input("\nEnter number of samples (default: 2000): ").strip()
        n_samples = int(n_samples) if n_samples else 2000
        df = create_sample_governance_dataset(n_samples=n_samples)
        file_name = "sample_governance_data.csv"

    else:
        print("Invalid choice. Exiting.")
        return None

    # Optional: Specify target column
    print(f"\n{'='*80}")
    print("Target Column Selection")
    print(f"{'='*80}")
    print("Available columns:")
    for idx, col in enumerate(df.columns, 1):
        unique_count = df[col].nunique()
        dtype = df[col].dtype
        print(f"  {idx:2}. {col:30} (unique: {unique_count:5}, dtype: {dtype})")

    print()
    target_input = input("Enter target column name (or press Enter for auto-detection): ").strip()
    target_column = target_input if target_input else None

    # Optional: Auto-approval threshold
    print()
    threshold_input = input("Enter auto-approval threshold (0.0-1.0, default: 0.80): ").strip()

    try:
        threshold = float(threshold_input) if threshold_input else 0.80
        threshold = max(0.0, min(1.0, threshold))
    except ValueError:
        print("Invalid threshold. Using default 0.80")
        threshold = 0.80

    print("\nSelect domain:")
    print("  1. Justice (default)")
    print("  2. Healthcare")
    print("  3. Finance")
    print("  4. Hiring")
    print("  5. Education")
    print("  6. Business")
    print("  7. Governance")
    domain_choice = input("Enter choice (1-7, default: 1): ").strip()

    if domain_choice == "2":
        domain = "health"
        jurisdiction = "NHS_England"
    elif domain_choice == "3":
        domain = "finance"
        jurisdiction = "FCA_UK"
    elif domain_choice == "4":
        domain = "hiring"
        jurisdiction = "ACAS_UK"
    elif domain_choice == "5":
        domain = "education"
        jurisdiction = "OFSTED_UK"
    elif domain_choice == "6":
        domain = "business"
        jurisdiction = "BEIS_UK"
    elif domain_choice == "7":
        domain = "governance"
        jurisdiction = "ELECTORAL_COMMISSION_UK"
    else:
        domain = "justice"
        jurisdiction = "US"

    # Initialize and run pipeline
    print(f"\n{'='*80}")
    print(f"INITIALIZING {domain.upper()} BIASCLEAN PIPELINE")
    print(f"{'='*80}\n")

    pipeline = UniversalBiasClean(domain=domain, jurisdiction=jurisdiction)

    # Run pipeline
    results = pipeline.process_dataset(
        df=df,
        target_column=target_column,
        auto_approve_threshold=threshold
    )

    # Display summary
    print("\n" + "="*80)
    print("QUICK RESULTS SUMMARY")
    print("="*80)

    diagnostics = results.get("diagnostics", {})
    validation = results.get("validation", {})

    print(f"\nPipeline completed successfully!")
    print(f"\nKey Metrics:")
    print(f"   • Initial Bias Score: {diagnostics.get('initial_bias_score', 0):.4f}")
    print(f"   • Final Bias Score: {diagnostics.get('final_bias_score', 0):.4f}")

    initial = diagnostics.get('initial_bias_score', 0)
    final = diagnostics.get('final_bias_score', 0)
    improvement = ((initial - final) / initial * 100) if initial > 0 else 0
    print(f"   • Overall Improvement: {improvement:+.1f}%")

    print(f"\nAll results saved to: biasclean_results/")
    print(f"   • Corrected dataset: corrected_dataset.csv")
    print(f"   • HTML report: biasclean_report.html")
    print(f"   • Visualizations: *.png files")

    return results

# ============================================================================
# 10. MAIN EXECUTION BLOCK
# ============================================================================

if __name__ == "__main__":
    print("""
    UNIVERSAL BIASCLEAN v2.1 - 7-DOMAIN EDITION

    Hierarchical Taxonomy + Constraint Validation Framework
    FIXED: Proper weight-based feature prioritization across all domains
    """)

    print("\nAVAILABLE FUNCTIONS:")
    print("="*80)
    print("\n1. run_interactive_pipeline()")
    print("   → Interactive mode with file upload and guided configuration")
    print("\n2. create_sample_justice_dataset(n_samples=2000)")
    print("   → Generate sample dataset for testing")
    print("\n3. UniversalBiasClean(domain='justice', jurisdiction='US')")
    print("   → Direct pipeline initialization for programmatic use")
    print("\n" + "="*80)

    print("\nQUICK START:")
    print("-"*80)
    print("\n# Option A: Interactive Mode (Recommended for first-time users)")
    print("results = run_interactive_pipeline()")

    print("\n# Option B: Programmatic Mode (For advanced users)")
    print("df = create_sample_justice_dataset(n_samples=2000)")
    print("pipeline = UniversalBiasClean(domain='justice', jurisdiction='california')")
    print("results = pipeline.process_dataset(df=df, auto_approve_threshold=0.85)")

    print("\n# Option C: Use Your Own CSV")
    print("pipeline = UniversalBiasClean(domain='justice')")
    print("results = pipeline.process_dataset(file_path='your_data.csv')")

    print("\n" + "="*80)
    print("\nTO BEGIN: Run one of the commands above in a new cell\n")

# ============================================================================
# 11. UTILITY FUNCTIONS FOR COLAB
# ============================================================================

def quick_start_sample():
    """Quick start with sample data - one-line execution"""
    print("QUICK START: Running BiasClean with sample data...\n")

    # Generate sample data
    df = create_sample_justice_dataset(n_samples=2000)

    # Run pipeline
    pipeline = UniversalBiasClean(domain="justice", jurisdiction="california")
    results = pipeline.process_dataset(
        df=df,
        auto_approve_threshold=0.80
    )

    return results

def quick_start_csv(file_path: str, target_column: str = None, domain: str = "justice"):
    """
    Quick start with your CSV file

    Args:
        file_path: Path to your CSV file
        target_column: Optional target column name
        domain: Domain for analysis (justice, health, finance, hiring, education, business, governance)

    Returns:
        Pipeline results
    """
    # Validate domain parameter
    valid_domains = ["justice", "health", "finance", "hiring", "education", "business", "governance"]
    if domain not in valid_domains:
        print(f"Invalid domain: {domain}. Must be one of: {', '.join(valid_domains)}")
        print("Defaulting to 'justice' domain.")
        domain = "justice"

    jurisdiction_map = {
        "justice": "US",
        "health": "NHS_England",
        "finance": "FCA_UK",
        "hiring": "ACAS_UK",
        "education": "OFSTED_UK",
        "business": "BEIS_UK",
        "governance": "ELECTORAL_COMMISSION_UK"
    }

    jurisdiction = jurisdiction_map.get(domain, "US")

    print(f"QUICK START: Running {domain} BiasClean on {file_path}...\n")

    pipeline = UniversalBiasClean(domain=domain, jurisdiction=jurisdiction)
    results = pipeline.process_dataset(
        file_path=file_path,
        target_column=target_column,
        auto_approve_threshold=0.80
    )

    return results

def display_results_summary(results: Dict):
    """Display formatted results summary in Colab"""
    from IPython.display import display, HTML

    diagnostics = results.get("diagnostics", {})
    validation = results.get("validation", {})
    mappings = results.get("mappings", {})

    html = f"""
    <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                padding: 20px; border-radius: 10px; color: white; margin: 20px 0;'>
        <h2 style='margin: 0 0 15px 0;'>BiasClean Results Summary</h2>
        <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 5px;'>
            <h3 style='margin-top: 0;'>Bias Reduction</h3>
            <p style='font-size: 24px; margin: 10px 0;'>
                <strong>{diagnostics.get('initial_bias_score', 0):.4f}</strong> →
                <strong>{diagnostics.get('final_bias_score', 0):.4f}</strong>
            </p>
            <p style='font-size: 18px;'>
                Improvement: <strong>{((diagnostics.get('initial_bias_score', 0) - diagnostics.get('final_bias_score', 0)) / diagnostics.get('initial_bias_score', 1) * 100) if diagnostics.get('initial_bias_score', 0) > 0 else 0:+.1f}%</strong>
            </p>
        </div>
        <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 5px; margin-top: 10px;'>
            <h3 style='margin-top: 0;'>Data Integrity</h3>
            <p style='margin: 5px 0;'>
                Retention Rate: <strong>{validation.get('data_integrity', {}).get('retention_rate', 100):.1f}%</strong>
            </p>
            <p style='margin: 5px 0;'>
                Records: <strong>{validation.get('data_integrity', {}).get('records_before', 0):,}</strong> →
                <strong>{validation.get('data_integrity', {}).get('records_after', 0):,}</strong>
            </p>
        </div>
        <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 5px; margin-top: 10px;'>
            <h3 style='margin-top: 0;'>Features Analyzed</h3>
            <p style='margin: 5px 0;'>
                Mapped Features: <strong>{len(mappings)}</strong>
            </p>
            <p style='margin: 5px 0;'>
                Significant Biases: <strong>{diagnostics.get('significant_bias_count', 0)}</strong>
            </p>
        </div>
    </div>
    """

    display(HTML(html))

    improvements = validation.get("fairness_improvement", {})
    if improvements:
        print("\nFAIRNESS IMPROVEMENTS BY FEATURE")
        print("="*80)

        for feature, imp_value in improvements.items():
            icon = "✅" if imp_value > 0 else "⚠️"
            bar_length = int(abs(imp_value) / 2)
            bar = "█" * min(bar_length, 50)
            print(f"{icon} {feature:25} {imp_value:+6.1f}% {bar}")

def download_results():
    """Download all results files from Colab to local machine"""
    try:
        from google.colab import files
        import os
        import zipfile

        print("Preparing results for download...\n")

        # Create zip file
        zip_path = "biasclean_results.zip"

        with zipfile.ZipFile(zip_path, 'w') as zipf:
            if os.path.exists("biasclean_results"):
                for root, dirs, file_list in os.walk("biasclean_results"):
                    for file in file_list:
                        file_path = os.path.join(root, file)
                        zipf.write(file_path, os.path.basename(file_path))

        print(f"Created: {zip_path}")
        print(f"   Contains: corrected_dataset.csv, HTML report, visualizations, and more")
        print("\nDownloading...")

        files.download(zip_path)

        print("Download complete!")
    except ImportError:
        print("Google Colab not available. Results are in the 'biasclean_results' directory.")
    except Exception as e:
        print(f"Download failed: {str(e)}")

def compare_datasets(original_df: pd.DataFrame, corrected_df: pd.DataFrame,
                    target_column: str, feature_column: str):
    """Interactive comparison of original vs corrected datasets"""
    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Original rates
    original_rates = original_df.groupby(feature_column)[target_column].mean()
    original_rates.plot(kind='bar', ax=axes[0], color='#e74c3c', alpha=0.7)
    axes[0].set_title('Before BiasClean', fontsize=14, fontweight='bold')
    axes[0].set_ylabel('Outcome Rate', fontsize=12)
    axes[0].axhline(y=original_df[target_column].mean(), color='black',
                   linestyle='--', label='Overall Mean', alpha=0.5)
    axes[0].legend()
    axes[0].set_ylim(0, 1)

    # Corrected rates
    corrected_rates = corrected_df.groupby(feature_column)[target_column].mean()
    corrected_rates.plot(kind='bar', ax=axes[1], color='#27ae60', alpha=0.7)
    axes[1].set_title('After BiasClean', fontsize=14, fontweight='bold')
    axes[1].set_ylabel('Outcome Rate', fontsize=12)
    axes[1].axhline(y=corrected_df[target_column].mean(), color='black',
                   linestyle='--', label='Overall Mean', alpha=0.5)
    axes[1].legend()
    axes[1].set_ylim(0, 1)

    plt.tight_layout()
    plt.show()

    # Print statistics
    print("\nSTATISTICAL COMPARISON")
    print("="*80)
    print(f"\nFeature: {feature_column}")
    print(f"Target: {target_column}\n")

    print(f"{'Group':<20} {'Before':<15} {'After':<15} {'Change':<15}")
    print("-"*65)

    for group in original_rates.index:
        before = original_rates.get(group, 0)
        after = corrected_rates.get(group, 0)
        change = after - before
        print(f"{str(group):<20} {before:<15.3f} {after:<15.3f} {change:+.3f}")

    before_disparity = original_rates.max() - original_rates.min()
    after_disparity = corrected_rates.max() - corrected_rates.min()
    disparity_reduction = ((before_disparity - after_disparity) / before_disparity * 100)

    print("\n" + "="*80)
    print(f"Disparity (max-min): {before_disparity:.3f} → {after_disparity:.3f}")
    print(f"Disparity Reduction: {disparity_reduction:+.1f}%")
    print("="*80)

# ============================================================================
# 12. ADVANCED FEATURES
# ============================================================================

def batch_process_datasets(file_paths: List[str],
                          output_dir: str = "batch_results",
                          domain: str = "justice") -> Dict[str, Any]:
    """Process multiple datasets in batch mode"""
    os.makedirs(output_dir, exist_ok=True)

    batch_results = {}

    print(f"\n{'='*80}")
    print(f"BATCH PROCESSING: {len(file_paths)} datasets")
    print(f"{'='*80}\n")

    for idx, file_path in enumerate(file_paths, 1):
        print(f"\n[{idx}/{len(file_paths)}] Processing: {file_path}")
        print("-"*80)

        try:
            dataset_name = os.path.splitext(os.path.basename(file_path))[0]
            dataset_dir = os.path.join(output_dir, dataset_name)
            os.makedirs(dataset_dir, exist_ok=True)

            pipeline = UniversalBiasClean(domain=domain)
            results = pipeline.process_dataset(
                file_path=file_path,
                auto_approve_threshold=0.80
            )

            results["corrected_df"].to_csv(
                os.path.join(dataset_dir, "corrected_dataset.csv"),
                index=False
            )

            batch_results[dataset_name] = {
                "success": True,
                "initial_bias": results["diagnostics"]["initial_bias_score"],
                "final_bias": results["diagnostics"]["final_bias_score"],
                "improvement": ((results["diagnostics"]["initial_bias_score"] -
                               results["diagnostics"]["final_bias_score"]) /
                               results["diagnostics"]["initial_bias_score"] * 100),
                "output_dir": dataset_dir
            }

            print(f"Success: {dataset_name}")

        except Exception as e:
            print(f"Failed: {file_path}")
            print(f"   Error: {str(e)}")
            batch_results[dataset_name] = {
                "success": False,
                "error": str(e)
            }

    print(f"\n{'='*80}")
    print("BATCH PROCESSING SUMMARY")
    print(f"{'='*80}\n")

    successful = sum(1 for r in batch_results.values() if r.get("success"))
    failed = len(batch_results) - successful

    print(f"Total Datasets: {len(batch_results)}")
    print(f"Successful:  {successful}")
    print(f"Failed:      {failed}")

    if successful > 0:
        avg_improvement = np.mean([
            r["improvement"] for r in batch_results.values()
            if r.get("success")
        ])
        print(f"\nAverage Improvement: {avg_improvement:+.1f}%")

    with open(os.path.join(output_dir, "batch_summary.json"), "w") as f:
        json.dump(batch_results, f, indent=2, default=str)

    print(f"\nBatch summary saved to: {output_dir}/batch_summary.json")
    print(f"{'='*80}\n")

    return batch_results

def export_to_format(results: Dict, format: str = "all"):
    """Export results to various formats"""
    corrected_df = results.get("corrected_df")

    if corrected_df is None:
        print("No corrected dataset found in results")
        return

    os.makedirs("biasclean_results/exports", exist_ok=True)

    formats_to_export = []
    if format == "all":
        formats_to_export = ["csv", "json", "excel"]
    else:
        formats_to_export = [format]

    print(f"\nEXPORTING RESULTS")
    print("="*80)

    for fmt in formats_to_export:
        try:
            if fmt == "csv":
                path = "biasclean_results/exports/corrected_dataset.csv"
                corrected_df.to_csv(path, index=False)
                print(f"CSV:   {path}")

            elif fmt == "json":
                path = "biasclean_results/exports/corrected_dataset.json"
                corrected_df.to_json(path, orient="records", indent=2)
                print(f"JSON:  {path}")

            elif fmt == "excel":
                path = "biasclean_results/exports/corrected_dataset.xlsx"
                corrected_df.to_excel(path, index=False, engine='openpyxl')
                print(f"Excel: {path}")

        except Exception as e:
            print(f"{fmt.upper()} export failed: {str(e)}")

    print("="*80)

# ============================================================================
# 13. HELP & DOCUMENTATION (7 DOMAINS)
# ============================================================================

def show_help():
    """Display comprehensive help documentation"""

    # UNIVERSAL BIASCLEAN v2.1 - 7-DOMAIN EDITION
    #
    # QUICK START FUNCTIONS:
    #
    # 1. run_interactive_pipeline()
    #    - Guided interface with file upload and configuration
    #    - Best for first-time users
    #
    # 2. quick_start_sample()
    #    - One-line execution with generated sample data
    #    - Perfect for testing and demonstrations
    #
    # 3. quick_start_csv('your_file.csv')
    #    - One-line execution with your own CSV
    #    - Fast processing for known datasets
    #
    # ─────────────────────────────────────────────────────────────────────────────
    #
    # DOMAIN WEIGHTS (FIXED PRIORITIZATION) - 7 DOMAINS (UK 2025 METHODOLOGY):
    #
    # JUSTICE Domain (Highest to Lowest Priority):
    #   1. Ethnicity (0.25) - HIGHEST PRIORITY
    #   2. SocioeconomicStatus (0.20)
    #   3. Region (0.15), Age (0.15) - Equal priority
    #   4. MigrationStatus (0.10), DisabilityStatus (0.10)
    #   5. Gender (0.05) - LOWEST PRIORITY
    #
    # HEALTH Domain (Highest to Lowest Priority):
    #   1. Ethnicity (0.25) - HIGHEST PRIORITY
    #   2. SocioeconomicStatus (0.20)
    #   3. DisabilityStatus (0.15), Gender (0.15) - Equal priority
    #   4. Region (0.10), Age (0.10)
    #   5. MigrationStatus (0.05) - LOWEST PRIORITY
    #
    # FINANCE Domain (Highest to Lowest Priority):
    #   1. SocioeconomicStatus (0.30) - HIGHEST PRIORITY
    #   2. Ethnicity (0.20), Region (0.20) - Equal priority
    #   3. Age (0.10), Gender (0.10) - Equal priority
    #   4. MigrationStatus (0.05), DisabilityStatus (0.05) - LOWEST PRIORITY
    #
    # EDUCATION Domain (Highest to Lowest Priority):
    #   1. SocioeconomicStatus (0.25) - HIGHEST PRIORITY
    #   2. Ethnicity (0.20)
    #   3. DisabilityStatus (0.15)
    #   4. Region (0.15)
    #   5. Gender (0.10), Age (0.10) - Equal priority
    #   6. MigrationStatus (0.05) - LOWEST PRIORITY
    #
    # HIRING Domain (Highest to Lowest Priority):
    #   1. Ethnicity (0.25) - HIGHEST PRIORITY
    #   2. Gender (0.20)
    #   3. DisabilityStatus (0.15), SocioeconomicStatus (0.15) - Equal priority
    #   4. Region (0.10), Age (0.10) - Equal priority
    #   5. MigrationStatus (0.05) - LOWEST PRIORITY
    #
    # BUSINESS Domain (Highest to Lowest Priority):
    #   1. Ethnicity (0.25) - HIGHEST PRIORITY
    #   2. Gender (0.20)
    #   3. Region (0.15), SocioeconomicStatus (0.15) - Equal priority
    #   4. Age (0.10), DisabilityStatus (0.10) - Equal priority
    #   5. MigrationStatus (0.05) - LOWEST PRIORITY
    #
    # GOVERNANCE Domain (Highest to Lowest Priority):
    #   1. Ethnicity (0.25) - HIGHEST PRIORITY
    #   2. Gender (0.20)
    #   3. Region (0.15), SocioeconomicStatus (0.15) - Equal priority
    #   4. MigrationStatus (0.10), DisabilityStatus (0.10) - Equal priority
    #   5. Age (0.05) - LOWEST PRIORITY
    #
    # ─────────────────────────────────────────────────────────────────────────────
    #
    # ADVANCED USAGE:
    #
    # # Initialize pipeline with custom settings
    # pipeline = UniversalBiasClean(
    #     domain='justice',              # Domain: 'justice', 'health', 'finance', 'hiring', 'education', 'business', 'governance'
    #     jurisdiction='california'      # Jurisdiction for compliance
    # )
    #
    # # Process dataset with options
    # results = pipeline.process_dataset(
    #     file_path='data.csv',          # OR df=your_dataframe
    #     target_column='outcome',       # Optional: auto-detected if None
    #     auto_approve_threshold=0.85    # Confidence threshold (0.0-1.0)
    # )
    #
    # ─────────────────────────────────────────────────────────────────────────────
    #
    # OUTPUT FILES (saved to biasclean_results/):
    #
    # - corrected_dataset.csv          - Bias-mitigated dataset
    # - biasclean_report.html         - Comprehensive HTML report
    # - feature_mappings.json         - Column mapping decisions
    # - pipeline_summary.json         - Execution summary
    # - disparity_comparison.png      - Before/after visualization
    # - fairness_improvements.png     - Feature improvements chart
    # - data_integrity.png            - Data retention metrics
    #
    # ─────────────────────────────────────────────────────────────────────────────
    #
    # EXAMPLES:
    #
    # # Example 1: Interactive mode
    # results = run_interactive_pipeline()
    #
    # # Example 2: Quick test with sample data
    # results = quick_start_sample()
    # display_results_summary(results)
    #
    # # Example 3: Business domain with weight prioritization
    # df = create_sample_business_dataset(n_samples=2000)
    # pipeline = UniversalBiasClean(domain='business', jurisdiction='BEIS_UK')
    # results = pipeline.process_dataset(df=df, auto_approve_threshold=0.85)
    #
    # # Example 4: Governance domain with weight prioritization
    # df = create_sample_governance_dataset(n_samples=2000)
    # pipeline = UniversalBiasClean(domain='governance', jurisdiction='ELECTORAL_COMMISSION_UK')
    # results = pipeline.process_dataset(df=df, auto_approve_threshold=0.85)
    #
    # # Example 5: Compare business funding results
    # compare_datasets(
    #     results['original_df'],
    #     results['corrected_df'],
    #     target_column='funding_approved',
    #     feature_column='owner_ethnicity'
    # )
    #
    # # Example 6: Test all 7 domains
    # for domain in ['justice', 'health', 'finance', 'hiring', 'education', 'business', 'governance']:
    #     print(f"Testing {domain} domain...")
    #     # Generate and test each domain
    #
    # ─────────────────────────────────────────────────────────────────────────────
    #
    # PIPELINE PHASES:
    #
    # 1. Dataset Loading          - Load CSV or DataFrame
    # 2. Hierarchical Mapping     - 3-tier feature detection
    # 3. Constraint Validation    - Statistical quality checks
    # 4. Mapping Confirmation     - Auto-approval based on confidence
    # 5. Preparation              - Build feature map for analysis
    # 6. Bias Detection           - Statistical tests (Fisher's, Chi-square)
    # 7. Bias Mitigation          - WEIGHT-PRIORITIZED rebalancing
    # 8. Results Compilation      - Package all outputs
    # 9. Save Results             - Write files to disk
    # 10. Generate Reports        - HTML reports and visualizations
    #
    # ─────────────────────────────────────────────────────────────────────────────
    #
    # KEY FEATURES:
    #
    # ✓ Hierarchical Taxonomy:     Universal → Domain → Jurisdiction
    # ✓ Constraint Validation:     Statistical quality checks
    # ✓ Auto-Approval:            Confidence-based mapping
    # ✓ Weight-Prioritization:    Higher weight = Higher mitigation priority
    # ✓ Comprehensive Reports:    HTML, JSON, visualizations
    # ✓ Legal Compliance:         GDPR, ECOA, Loomis standards
    # ✓ Batch Processing:         Multiple datasets at once
    # ✓ Colab Integration:        Upload, process, download
    #
    # ─────────────────────────────────────────────────────────────────────────────
    #
    # MORE INFORMATION:
    #
    # - GitHub: [Your repo URL]
    # - Documentation: [Your docs URL]
    # - Paper: "Universal BiasClean: Hierarchical Taxonomy + Constraint Validation"

    # Print the actual help content
    print("UNIVERSAL BIASCLEAN v2.1 - 7-DOMAIN EDITION")
    print("\n" + "="*80)
    print("QUICK START FUNCTIONS:")
    print("="*80)
    print("\n1. run_interactive_pipeline()")
    print("   - Guided interface with file upload and configuration")
    print("   - Best for first-time users")
    print("\n2. quick_start_sample()")
    print("   - One-line execution with generated sample data")
    print("   - Perfect for testing and demonstrations")
    print("\n3. quick_start_csv('your_file.csv')")
    print("   - One-line execution with your own CSV")
    print("   - Fast processing for known datasets")

    print("\n" + "="*80)
    print("DOMAIN WEIGHTS (FIXED PRIORITIZATION) - 7 DOMAINS (UK 2025 METHODOLOGY):")
    print("="*80)

    print("\nJUSTICE Domain (Highest to Lowest Priority):")
    print("  1. Ethnicity (0.25) - HIGHEST PRIORITY")
    print("  2. SocioeconomicStatus (0.20)")
    print("  3. Region (0.15), Age (0.15) - Equal priority")
    print("  4. MigrationStatus (0.10), DisabilityStatus (0.10)")
    print("  5. Gender (0.05) - LOWEST PRIORITY")

    print("\nHEALTH Domain (Highest to Lowest Priority):")
    print("  1. Ethnicity (0.25) - HIGHEST PRIORITY")
    print("  2. SocioeconomicStatus (0.20)")
    print("  3. DisabilityStatus (0.15), Gender (0.15) - Equal priority")
    print("  4. Region (0.10), Age (0.10)")
    print("  5. MigrationStatus (0.05) - LOWEST PRIORITY")

    print("\nFINANCE Domain (Highest to Lowest Priority):")
    print("  1. SocioeconomicStatus (0.30) - HIGHEST PRIORITY")
    print("  2. Ethnicity (0.20), Region (0.20) - Equal priority")
    print("  3. Age (0.10), Gender (0.10) - Equal priority")
    print("  4. MigrationStatus (0.05), DisabilityStatus (0.05) - LOWEST PRIORITY")

    print("\nEDUCATION Domain (Highest to Lowest Priority):")
    print("  1. SocioeconomicStatus (0.25) - HIGHEST PRIORITY")
    print("  2. Ethnicity (0.20)")
    print("  3. DisabilityStatus (0.15)")
    print("  4. Region (0.15)")
    print("  5. Gender (0.10), Age (0.10) - Equal priority")
    print("  6. MigrationStatus (0.05) - LOWEST PRIORITY")

    print("\nHIRING Domain (Highest to Lowest Priority):")
    print("  1. Ethnicity (0.25) - HIGHEST PRIORITY")
    print("  2. Gender (0.20)")
    print("  3. DisabilityStatus (0.15), SocioeconomicStatus (0.15) - Equal priority")
    print("  4. Region (0.10), Age (0.10) - Equal priority")
    print("  5. MigrationStatus (0.05) - LOWEST PRIORITY")

    print("\nBUSINESS Domain (Highest to Lowest Priority):")
    print("  1. Ethnicity (0.25) - HIGHEST PRIORITY")
    print("  2. Gender (0.20)")
    print("  3. Region (0.15), SocioeconomicStatus (0.15) - Equal priority")
    print("  4. Age (0.10), DisabilityStatus (0.10) - Equal priority")
    print("  5. MigrationStatus (0.05) - LOWEST PRIORITY")

    print("\nGOVERNANCE Domain (Highest to Lowest Priority):")
    print("  1. Ethnicity (0.25) - HIGHEST PRIORITY")
    print("  2. Gender (0.20)")
    print("  3. Region (0.15), SocioeconomicStatus (0.15) - Equal priority")
    print("  4. MigrationStatus (0.10), DisabilityStatus (0.10) - Equal priority")
    print("  5. Age (0.05) - LOWEST PRIORITY")

    print("\n" + "="*80)
    print("ADVANCED USAGE:")
    print("="*80)
    print("\n# Initialize pipeline with custom settings")
    print("pipeline = UniversalBiasClean(")
    print("    domain='justice',              # Domain: 'justice', 'health', 'finance', 'hiring', 'education', 'business', 'governance'")
    print("    jurisdiction='california'      # Jurisdiction for compliance")
    print(")")
    print("\n# Process dataset with options")
    print("results = pipeline.process_dataset(")
    print("    file_path='data.csv',          # OR df=your_dataframe")
    print("    target_column='outcome',       # Optional: auto-detected if None")
    print("    auto_approve_threshold=0.85    # Confidence threshold (0.0-1.0)")
    print(")")

    print("\n" + "="*80)
    print("OUTPUT FILES (saved to biasclean_results/):")
    print("="*80)
    print("\n- corrected_dataset.csv          - Bias-mitigated dataset")
    print("- biasclean_report.html         - Comprehensive HTML report")
    print("- feature_mappings.json         - Column mapping decisions")
    print("- pipeline_summary.json         - Execution summary")
    print("- disparity_comparison.png      - Before/after visualization")
    print("- fairness_improvements.png     - Feature improvements chart")
    print("- data_integrity.png            - Data retention metrics")

    print("\n" + "="*80)
    print("EXAMPLES:")
    print("="*80)
    print("\n# Example 1: Interactive mode")
    print("results = run_interactive_pipeline()")
    print("\n# Example 2: Quick test with sample data")
    print("results = quick_start_sample()")
    print("display_results_summary(results)")
    print("\n# Example 3: Business domain with weight prioritization")
    print("df = create_sample_business_dataset(n_samples=2000)")
    print("pipeline = UniversalBiasClean(domain='business', jurisdiction='BEIS_UK')")
    print("results = pipeline.process_dataset(df=df, auto_approve_threshold=0.85)")
    print("\n# Example 4: Governance domain with weight prioritization")
    print("df = create_sample_governance_dataset(n_samples=2000)")
    print("pipeline = UniversalBiasClean(domain='governance', jurisdiction='ELECTORAL_COMMISSION_UK')")
    print("results = pipeline.process_dataset(df=df, auto_approve_threshold=0.85)")
    print("\n# Example 5: Compare business funding results")
    print("compare_datasets(")
    print("    results['original_df'],")
    print("    results['corrected_df'],")
    print("    target_column='funding_approved',")
    print("    feature_column='owner_ethnicity'")
    print(")")
    print("\n# Example 6: Test all 7 domains")
    print("for domain in ['justice', 'health', 'finance', 'hiring', 'education', 'business', 'governance']:")
    print('    print(f"Testing {domain} domain...")')
    print("    # Generate and test each domain")

    print("\n" + "="*80)
    print("PIPELINE PHASES:")
    print("="*80)
    print("\n1. Dataset Loading          - Load CSV or DataFrame")
    print("2. Hierarchical Mapping     - 3-tier feature detection")
    print("3. Constraint Validation    - Statistical quality checks")
    print("4. Mapping Confirmation     - Auto-approval based on confidence")
    print("5. Preparation              - Build feature map for analysis")
    print("6. Bias Detection           - Statistical tests (Fisher's, Chi-square)")
    print("7. Bias Mitigation          - WEIGHT-PRIORITIZED rebalancing")
    print("8. Results Compilation      - Package all outputs")
    print("9. Save Results             - Write files to disk")
    print("10. Generate Reports        - HTML reports and visualizations")

    print("\n" + "="*80)
    print("KEY FEATURES:")
    print("="*80)
    print("\n✓ Hierarchical Taxonomy:     Universal → Domain → Jurisdiction")
    print("✓ Constraint Validation:     Statistical quality checks")
    print("✓ Auto-Approval:            Confidence-based mapping")
    print("✓ Weight-Prioritization:    Higher weight = Higher mitigation priority")
    print("✓ Comprehensive Reports:    HTML, JSON, visualizations")
    print("✓ Legal Compliance:         GDPR, ECOA, Loomis standards")
    print("✓ Batch Processing:         Multiple datasets at once")
    print("✓ Colab Integration:        Upload, process, download")

    print("\n" + "="*80)
    print("MORE INFORMATION:")
    print("="*80)
    print("\n- GitHub: [Your repo URL]")
    print("- Documentation: [Your docs URL]")
    print('- Paper: "Universal BiasClean: Hierarchical Taxonomy + Constraint Validation"')
    print("\n" + "="*80)

    # ============================================================================
# 14. INITIALIZATION & USAGE INSTRUCTIONS
# ============================================================================

def show_welcome():
    """Display welcome message"""
    print("\n" + "="*80)
    print("UNIVERSAL BIASCLEAN v2.1 - 7-DOMAIN EDITION")
    print("="*80)
    print("\nSUCCESSFULLY LOADED WITH 7 DOMAINS:")
    print("1. Justice    - Criminal justice bias detection")
    print("2. Health     - Healthcare bias analysis")
    print("3. Finance    - Financial services fairness")
    print("4. Hiring     - Employment & recruitment bias")
    print("5. Education  - Educational access & attainment bias")
    print("6. Business   - Business funding & investment bias")
    print("7. Governance - Political representation & selection bias")
    print("\nAvailable Functions:")
    print("1. run_interactive_pipeline()   - Interactive mode with upload")
    print("2. quick_start_sample()         - Test with sample data")
    print("3. quick_start_csv(file_path)   - Process your CSV file")
    print("\nQuick Start (run in a new cell):")
    print("    results = quick_start_sample()          # Test with sample data")
    print("    results = run_interactive_pipeline()    # Interactive mode")
    print("\nFor help: show_help()")
    print("\nFIXED: Weight-based prioritization now works correctly for ALL 7 domains")
    print("="*80 + "\n")

# Show welcome message
show_welcome()

# ============================================================================
# 15. MAIN EXECUTION BLOCK - FIXED (NO TRIPLE QUOTES)
# ============================================================================

if __name__ == "__main__":
    print("Executing BiasClean Pipeline in interactive mode...\n")

    print("UNIVERSAL BIASCLEAN v2.1 - 7-DOMAIN EDITION")
    print("\nHierarchical Taxonomy + Constraint Validation Framework")
    print("FIXED: Proper weight-based feature prioritization across all domains\n")

    print("AVAILABLE FUNCTIONS:")
    print("="*80)
    print("\n1. run_interactive_pipeline()")
    print("   → Interactive mode with file upload and guided configuration")
    print("\n2. create_sample_justice_dataset(n_samples=2000)")
    print("   → Generate sample dataset for testing")
    print("\n3. UniversalBiasClean(domain='justice', jurisdiction='US')")
    print("   → Direct pipeline initialization for programmatic use")
    print("\n" + "="*80)

    print("\nQUICK START:")
    print("-"*80)
    print("\n# Option A: Interactive Mode (Recommended for first-time users)")
    print("results = run_interactive_pipeline()")
    print("\n# Option B: Programmatic Mode (For advanced users)")
    print("df = create_sample_justice_dataset(n_samples=2000)")
    print("pipeline = UniversalBiasClean(domain='justice', jurisdiction='california')")
    print("results = pipeline.process_dataset(df=df, auto_approve_threshold=0.85)")
    print("\n# Option C: Use Your Own CSV")
    print("pipeline = UniversalBiasClean(domain='justice')")
    print("results = pipeline.process_dataset(file_path='your_data.csv')")
    print("\n" + "="*80)

    print("\nTO BEGIN: Run one of the commands above in a new cell\n")

    # Run interactive pipeline
    results = run_interactive_pipeline()

"""# Flask API Server"""

# ============================================================================
# FINAL CELL: Save Minimal Flask Wrapper for Render.com
# ============================================================================

flask_wrapper_code = '''
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import pandas as pd
import os
import uuid
import tempfile
import json
from datetime import datetime

app = Flask(__name__)
CORS(app)

app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024
app.config['UPLOAD_FOLDER'] = tempfile.gettempdir()

print("🚀 BiasClean Flask Wrapper Initialized")

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "service": "BiasClean v2.1 - 7 Domain Edition",
        "timestamp": datetime.now().isoformat(),
        "domains": ["justice", "health", "finance", "hiring", "education", "business", "governance"]
    })

@app.route('/biasclean/biasclean-audit', methods=['POST'])
def biasclean_audit():
    try:
        if 'file' not in request.files:
            return jsonify({"error": "No file uploaded"}), 400

        file = request.files['file']
        domain = request.form.get('domain', 'justice')

        if file.filename == '':
            return jsonify({"error": "No file selected"}), 400

        if not file.filename.lower().endswith('.csv'):
            return jsonify({"error": "Only CSV files allowed"}), 400

        # Create session
        session_id = str(uuid.uuid4())
        session_dir = os.path.join(app.config['UPLOAD_FOLDER'], f"biasclean_{session_id}")
        os.makedirs(session_dir, exist_ok=True)

        # Save file
        input_path = os.path.join(session_dir, "uploaded_dataset.csv")
        file.save(input_path)
        df = pd.read_csv(input_path)

        # USE YOUR EXISTING PIPELINE
        from biasclean_7 import UniversalBiasClean

        # Initialize with domain
        jurisdictions = {
            'justice': 'US', 'health': 'NHS_England', 'finance': 'FCA_UK',
            'hiring': 'ACAS_UK', 'education': 'OFSTED_UK',
            'business': 'BEIS_UK', 'governance': 'ELECTORAL_COMMISSION_UK'
        }
        jurisdiction = jurisdictions.get(domain, 'Default')

        pipeline = UniversalBiasClean(domain=domain, jurisdiction=jurisdiction)
        results = pipeline.process_dataset(df=df, auto_approve_threshold=0.80)

        # Save results
        corrected_path = os.path.join(session_dir, "corrected_dataset.csv")
        results['corrected_df'].to_csv(corrected_path, index=False)

        report_path = os.path.join(session_dir, "biasclean_report.html")
        results['reporter'].generate_html_report(results, report_path)

        validation_path = os.path.join(session_dir, "validation.json")
        with open(validation_path, 'w') as f:
            json.dump(results['validation'], f, default=str)

        # Format response
        diagnostics = results.get('diagnostics', {})
        validation = results.get('validation', {})

        initial_bias = diagnostics.get('initial_bias_score', 0)
        final_bias = diagnostics.get('final_bias_score', initial_bias)
        bias_reduction = ((initial_bias - final_bias) / initial_bias * 100) if initial_bias > 0 else 0

        response = {
            "success": True,
            "session_id": session_id,
            "detection": {
                "n_rows": len(df),
                "n_columns": len(df.columns),
                "significant_biases": diagnostics.get('significant_bias_count', 0)
            },
            "removal": {
                "bias_reduction_percent": round(bias_reduction, 1),
                "data_retention_percent": validation.get('data_integrity', {}).get('retention_rate', 100),
                "production_ready": bias_reduction > 20
            },
            "files": {
                "corrected": "corrected_dataset.csv",
                "report": "biasclean_report.html",
                "validation": "validation.json"
            },
            "report_content": f"BiasClean Analysis Complete\\nBias Reduction: {bias_reduction:.1f}%\\nData Retention: {validation.get('data_integrity', {}).get('retention_rate', 100):.1f}%",
            "download_links": {
                "corrected": f"/biasclean/download/{session_id}/corrected_dataset.csv",
                "report": f"/biasclean/download/{session_id}/biasclean_report.html",
                "validation": f"/biasclean/download/{session_id}/validation.json"
            }
        }

        return jsonify(response)

    except Exception as e:
        print(f"❌ Error: {str(e)}")
        return jsonify({"error": "Processing failed", "message": str(e)}), 500

@app.route('/biasclean/download/<session_id>/<filename>', methods=['GET'])
def download_file(session_id, filename):
    try:
        allowed_files = ['corrected_dataset.csv', 'biasclean_report.html', 'validation.json']
        if filename not in allowed_files:
            return jsonify({"error": "Invalid filename"}), 400

        session_dir = os.path.join(app.config['UPLOAD_FOLDER'], f"biasclean_{session_id}")
        file_path = os.path.join(session_dir, filename)

        if not os.path.exists(file_path):
            return jsonify({"error": "File not found"}), 404

        return send_file(file_path, as_attachment=True, download_name=filename)

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/domains', methods=['GET'])
def get_domains():
    try:
        from biasclean_7 import DOMAIN_CONFIGS
        return jsonify(DOMAIN_CONFIGS)
    except:
        return jsonify({
            "justice": {"description": "Justice system bias analysis"},
            "health": {"description": "Healthcare bias analysis"},
            "finance": {"description": "Financial services bias analysis"},
            "hiring": {"description": "Hiring and recruitment bias analysis"},
            "education": {"description": "Education system bias analysis"},
            "business": {"description": "Business operations bias analysis"},
            "governance": {"description": "Governance and policy bias analysis"}
        })

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
'''

# Save the Flask wrapper to a file
with open('biasclean_app.py', 'w') as f:
    f.write(flask_wrapper_code)

# Create requirements.txt
requirements = '''Flask==2.3.3
Flask-CORS==4.0.0
pandas==2.1.4
numpy==1.24.3
scipy==1.11.3
matplotlib==3.8.0
seaborn==0.13.0
gunicorn==21.2.0
Werkzeug==3.0.1
'''

with open('requirements.txt', 'w') as f:
    f.write(requirements)

# Create Procfile
procfile = 'web: gunicorn --bind 0.0.0.0:$PORT --workers 2 --threads 4 --timeout 300 biasclean_app:app'

with open('Procfile', 'w') as f:
    f.write(procfile)

print("✅ All deployment files created:")
print("   • biasclean_app.py     - Flask wrapper")
print("   • requirements.txt     - Dependencies")
print("   • Procfile            - Render.com config")
print()
print("📁 Upload these files to GitHub with your biasclean_7.py:")
print("   - biasclean_7.py      (your main pipeline)")
print("   - biasclean_app.py    (this Flask wrapper)")
print("   - requirements.txt")
print("   - Procfile")
print()
print("🔗 Connect to Render.com, and your HTML form URL will be:")
print("   https://YOUR-APP.onrender.com/biasclean/biasclean-audit")
