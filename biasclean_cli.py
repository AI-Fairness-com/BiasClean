# -*- coding: utf-8 -*-
"""biasclean_cli.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zJxP-k_9IFLjrGDQmSBIFyFWNsShtJ-L
"""

"""
Command-line interface for BiasClean v2.0 (local only).

Four subcommands:
- detect
- remove  
- report
- visualize
"""

import argparse
from pprint import pprint

from biasclean_pipeline import (
    biasclean_detect,
    biasclean_remove,
    biasclean_report,
    biasclean_visualize,
)


def main():
    parser = argparse.ArgumentParser(
        description="BiasClean v2.0 â€” local bias cleaning pipeline"
    )

    subparsers = parser.add_subparsers(dest="command", required=True)

    # 1) DETECT
    p_detect = subparsers.add_parser(
        "detect",
        help="Compute baseline bias score for a dataset/domain",
    )
    p_detect.add_argument("--input", required=True, help="Path to input CSV")
    p_detect.add_argument(
        "--domain",
        required=True,
        choices=[
            "justice",
            "health",
            "finance",
            "education",
            "hiring",
            "business",
            "governance",
        ],
        help="Domain for BiasClean weighting",
    )

    # 2) REMOVE
    p_remove = subparsers.add_parser(
        "remove",
        help="Apply BiasClean and save corrected dataset",
    )
    p_remove.add_argument("--input", required=True, help="Path to input CSV")
    p_remove.add_argument(
        "--domain",
        required=True,
        choices=[
            "justice",
            "health",
            "finance",
            "education",
            "hiring",
            "business",
            "governance",
        ],
        help="Domain for BiasClean weighting",
    )
    p_remove.add_argument(
        "--mode",
        default="industry",
        choices=["industry", "strict"],
        help="BiasClean transformation mode",
    )
    p_remove.add_argument(
        "--output",
        default="biasclean_corrected.csv",
        help="Path to save corrected CSV",
    )

    # 3) REPORT
    p_report = subparsers.add_parser(
        "report",
        help="Generate BiasClean textual report",
    )
    p_report.add_argument("--input", required=True, help="Path to input CSV")
    p_report.add_argument(
        "--domain",
        required=True,
        choices=[
            "justice",
            "health",
            "finance",
            "education",
            "hiring",
            "business",
            "governance",
        ],
        help="Domain for BiasClean weighting",
    )
    p_report.add_argument(
        "--mode",
        default="industry",
        choices=["industry", "strict"],
        help="BiasClean transformation mode (used if correction is recomputed)",
    )
    p_report.add_argument(
        "--corrected",
        default=None,
        help="Optional path to existing corrected CSV (otherwise recomputed)",
    )
    p_report.add_argument(
        "--output",
        default="biasclean_report.txt",
        help="Path to save textual report",
    )

    # 4) VISUALIZE
    p_visualize = subparsers.add_parser(
        "visualize",
        help="Generate professional visualizations for bias mitigation results",
    )
    p_visualize.add_argument("--input", required=True, help="Path to original CSV")
    p_visualize.add_argument("--corrected", required=True, help="Path to corrected CSV")
    p_visualize.add_argument(
        "--domain",
        required=True,
        choices=[
            "justice", "health", "finance", "education", 
            "hiring", "business", "governance",
        ],
        help="Domain for BiasClean weighting",
    )
    p_visualize.add_argument(
        "--output-dir",
        default="biasclean_visualizations",
        help="Directory to save visualizations",
    )

    args = parser.parse_args()

    if args.command == "detect":
        result = biasclean_detect(args.input, args.domain)
        print("\n[BiasClean DETECT] baseline fairness stats:\n")
        pprint(result)

    elif args.command == "remove":
        summary, out_path = biasclean_remove(
            args.input,
            args.domain,
            mode=args.mode,
            output_path=args.output,
        )
        print("\n[BiasClean REMOVE] correction summary:\n")
        pprint(summary)
        print(f"\nCorrected dataset saved to: {out_path}")

    elif args.command == "report":
        report_path = biasclean_report(
            args.input,
            args.domain,
            mode=args.mode,
            report_path=args.output,
            corrected_path=args.corrected,
        )
        print(f"\n[BiasClean REPORT] report saved to: {report_path}")

    elif args.command == "visualize":
        viz_dir = biasclean_visualize(
            args.input,
            args.corrected,
            args.domain,
            output_dir=args.output_dir,
        )
        print(f"\n[BiasClean VISUALIZE] visualizations saved to: {viz_dir}")


if __name__ == "__main__":
    main()